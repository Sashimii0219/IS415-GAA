---
title: "Hands-on Exercise 9"
format: 
  html:
    code-fold: true
    code-summary: "Show code"
execute: 
  eval: true
  echo: true
  freeze: auto
  warning: false
date: "`r Sys.Date()`"
---

# 1. Learning Objective

# 2. Getting Started

## 2.1 Context

**Predictive modelling** uses statistical learning or machine learning techniques to predict outcomes. By and large, the event one wants to predict is in the future. However, a set of known outcome and predictors (also known as variables) will be used to calibrate the predictive models.

**Geospatial predictive modelling** is conceptually rooted in the principle that the occurrences of events being modeled are limited in distribution. When geographically referenced data are used, occurrences of events are neither uniform nor random in distribution over space. There are geospatial factors (infrastructure, sociocultural, topographic, etc.) that constrain and influence where the locations of events occur. Geospatial predictive modeling attempts to describe those constraints and influences by spatially correlating occurrences of historical geospatial locations with environmental factors that represent those constraints and influences.

In this exercise, we will learn how to build predictive model by using geographical random forest method. By the end of this hands-on exercise, you will acquire the skills of:

-   preparing training and test data sets by using appropriate data sampling methods,

-   calibrating predictive models by using both geospatial statistical learning and machine learning methods,

-   comparing and selecting the best model for predicting the future outcome,

-   predicting the future outcomes by using the best model calibrated.

## **2.2 Loading R Packages**

Here are the packages that we will be using today.

```{r}
pacman::p_load(sf, spdep, GWmodel, SpatialML, 
               tmap, rsample, Metrics, tidyverse)
```

## 2.3 Data Importing and Preparation

### 2.3.1 Dataset

-   **Aspatial dataset**:

    -   HDB Resale data: a list of HDB resale transacted prices in Singapore from Jan 2017 onwards. It is in csv format which can be downloaded from Data.gov.sg.

-   **Geospatial dataset**:

    -   *MP14_SUBZONE_WEB_PL*: a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg

-   **Locational factors with geographic coordinates**:

    -   Downloaded from **Data.gov.sg**.

        -   **Eldercare** data is a list of eldercare in Singapore. It is in shapefile format.

        -   **Hawker Centre** data is a list of hawker centres in Singapore. It is in geojson format.

        -   **Parks** data is a list of parks in Singapore. It is in geojson format.

        -   **Supermarket** data is a list of supermarkets in Singapore. It is in geojson format.

        -   **CHAS clinics** data is a list of CHAS clinics in Singapore. It is in geojson format.

        -   **Childcare service** data is a list of childcare services in Singapore. It is in geojson format.

        -   **Kindergartens** data is a list of kindergartens in Singapore. It is in geojson format.

    -   Downloaded from **Datamall.lta.gov.sg**.

        -   **MRT** data is a list of MRT/LRT stations in Singapore with the station names and codes. It is in shapefile format.

        -   **Bus stops** data is a list of bus stops in Singapore. It is in shapefile format.

-   **Locational factors without geographic coordinates**:

    -   Downloaded from **Data.gov.sg**.

        -   **Primary school** data is extracted from the list on General information of schools from data.gov portal. It is in csv format.

    -   Retrieved/Scraped from **other sources**

        -   **CBD** coordinates obtained from Google.

        -   **Shopping malls** data is a list of Shopping malls in Singapore obtained from [Wikipedia](https://en.wikipedia.org/wiki/List_of_shopping_malls_in_Singapore).

        -   **Good primary schools** is a list of primary schools that are ordered in ranking in terms of popularity and this can be found at [Local Salary Forum](https://www.salary.sg/2021/best-primary-schools-2021-by-popularity).

### 2.3.2 Importing Data

```{r}
mdata <- read_rds("data/aspatial/mdata.rds")
```

### 2.3.3 Data Sampling

The entire data are split into training and test data sets with 65% and 35% respectively by using *initial_split()* of **rsample** package. rsample is one of the package of tigymodels.

```{r}
set.seed(1234)
resale_split <- initial_split(mdata, 
                              prop = 6.5/10,)

train_data <- training(resale_split)
test_data <- testing(resale_split)
```

# **3. Computing Correlation Matrix**

Before loading the predictors into a predictive model, it is always a good practice to use correlation matrix to examine if there is sign of multicolinearity.

```{r}
mdata_nogeo <- mdata %>%
  st_drop_geometry()
corrplot::corrplot(cor(mdata_nogeo[, 2:17]), 
                   diag = FALSE, 
                   order = "AOE",
                   tl.pos = "td", 
                   tl.cex = 0.5, 
                   method = "number", 
                   type = "upper")
```

# **4. Building a non-spatial multiple linear regression**

```{r}
#| eval: false
price_mlr <- lm(resale_price ~ floor_area_sqm +
                  storey_order + remaining_lease_mths +
                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
                  PROX_MRT + PROX_PARK + PROX_MALL + 
                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                  WITHIN_1KM_PRISCH,
                data=train_data)
summary(price_mlr)
```

```{r}
#| eval: false
write_rds(price_mlr, "data/rds/price_mlr.rds" ) 
```

# **5. Gwr predictive method**

In this section, you will learn how to calibrate a model to predict HDB resale price by using geographically weighted regression method of **GWmodel** package.

## **5.1 Converting the sf data.frame to SpatialPointDataFrame**

```{r}
train_data_sp <- as_Spatial(train_data)
train_data_sp
```

## **5.2 Computing adaptive bandwidth**

Next, *`bw.gwr()`* of **GWmodel** package will be used to determine the optimal bandwidth to be used.

```{r}
#| eval: false
bw_adaptive <- bw.gwr(resale_price ~ floor_area_sqm +
                  storey_order + remaining_lease_mths +
                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
                  PROX_MRT + PROX_PARK + PROX_MALL + 
                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                  WITHIN_1KM_PRISCH,
                  data=train_data_sp,
                  approach="CV",
                  kernel="gaussian",
                  adaptive=TRUE,
                  longlat=FALSE)
```

```{r}
#| eval: false
write_rds(bw_adaptive, "data/rds/bw_adaptive.rds")
```

## **5.3 Constructing the adaptive bandwidth gwr model**

```{r}
bw_adaptive <- read_rds("data/rds/bw_adaptive.rds")
```

Now, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and Gaussian kernel as shown in the code chunk below.

```{r}
#| eval: false
gwr_adaptive <- gwr.basic(formula = resale_price ~
                            floor_area_sqm + storey_order +
                            remaining_lease_mths + PROX_CBD + 
                            PROX_ELDERLYCARE + PROX_HAWKER +
                            PROX_MRT + PROX_PARK + PROX_MALL + 
                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                            WITHIN_1KM_PRISCH,
                          data=train_data_sp,
                          bw=bw_adaptive, 
                          kernel = 'gaussian', 
                          adaptive=TRUE,
                          longlat = FALSE)
```

```{r}
#| eval: false
write_rds(gwr_adaptive, "data/rds/gwr_adaptive.rds")
```

## **5.4 Retrieve gwr output object**

```{r}
gwr_adaptive <- read_rds("data/rds/gwr_adaptive.rds")
```

```{r}
gwr_adaptive
```

## **5.5 Converting the test data from sf data.frame to SpatialPointDataFrame**

```{r}
test_data_sp <- test_data %>%
  as_Spatial()
test_data_sp
```

## 5.6 **Computing adaptive bandwidth for the test data**

```{r}
#| eval: false
gwr_bw_test_adaptive <- bw.gwr(resale_price ~ floor_area_sqm +
                  storey_order + remaining_lease_mths +
                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
                  PROX_MRT + PROX_PARK + PROX_MALL + 
                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                  WITHIN_1KM_PRISCH,
                  data=test_data_sp,
                  approach="CV",
                  kernel="gaussian",
                  adaptive=TRUE,
                  longlat=FALSE)
```

## **5.7 Computing predicted values of the test data**

```{r}
#| eval: false
gwr_pred <- gwr.predict(formula = resale_price ~
                          floor_area_sqm + storey_order +
                          remaining_lease_mths + PROX_CBD + 
                          PROX_ELDERLYCARE + PROX_HAWKER + 
                          PROX_MRT + PROX_PARK + PROX_MALL + 
                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + 
                          WITHIN_1KM_PRISCH, 
                        data=train_data_sp, 
                        predictdata = test_data_sp, 
                        bw=40, 
                        kernel = 'gaussian', 
                        adaptive=TRUE, 
                        longlat = FALSE)
```

# **6. Preparing coordinates data**

## 6.1 **Extracting coordinates data**

The code chunk below extract the x,y coordinates of the full, training and test data sets.

```{r}
coords <- st_coordinates(mdata)
coords_train <- st_coordinates(train_data)
coords_test <- st_coordinates(test_data)
```

## 6.2 **Droping geometry field**

First, we will drop geometry column of the sf data.frame by using *`st_drop_geometry()`* of sf package.

```{r}
train_data <- train_data %>% 
  st_drop_geometry()
```

# **7. Calibrating Random Forest Model**

In this section, we will learn how to calibrate a model to predict HDB resale price by using random forest function of **ranger** package.

```{r}
#| eval: false
set.seed(1234)
rf <- ranger(resale_price ~ floor_area_sqm + storey_order + 
               remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + 
               PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + 
               PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
               WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + 
               WITHIN_1KM_PRISCH,
             data=train_data)
rf
```

```{r}
#| eval: false
write_rds(rf, "data/rds/rf.rds")
```

```{r}
rf <- read_rds("data/rds/rf.rds")
rf
```

## 7.1 **Calibrating using training data**

The code chunk below calibrate a geographic ranform forest model by using *`grf()`* of **SpatialML** package.

```{r}
#| eval: false
set.seed(1234)
gwRF_adaptive <- grf(formula = resale_price ~ floor_area_sqm + storey_order +
                       remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE +
                       PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL +
                       PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                       WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                       WITHIN_1KM_PRISCH,
                     dframe=train_data, 
                     bw=55,
                     kernel="adaptive",
                     coords=coords_train)
```

```{r}
#| eval: false
write_rds(gwRF_adaptive, "data/rds/gwRF_adaptive.rds")
```

## 7.2 **Predicting by using test data**

The code chunk below will be used to combine the test data with its corresponding coordinates data.

```{r}
gwRF_adaptive <- read_rds("data/rds/gwRF_adaptive.rds")
```

```{r}
test_data <- cbind(test_data, coords_test) %>%
  st_drop_geometry()
```

Next, `predict.grf()` of spatialML package will be used to predict the resale value by using the test data and gwRF_adaptive model calibrated earlier.

```{r}
#| eval: false
gwRF_pred <- predict.grf(gwRF_adaptive, 
                           test_data, 
                           x.var.name="X",
                           y.var.name="Y", 
                           local.w=1,
                           global.w=0)
```

### Converting the predicting output into a data frame

```{r}
#| eval: false
GRF_pred <- write_rds(gwRF_pred, "data/rds/GRF_pred.rds")
```

```{r}
GRF_pred <- read_rds("data/rds/GRF_pred.rds")
GRF_pred_df <- as.data.frame(GRF_pred)
```

In the code chunk below, `cbind()` is used to append the predicted values onto test_datathe

```{r}
test_data_p <- cbind(test_data, GRF_pred_df)
```

### **Calculating Root Mean Square Error**

```{r}
rmse(test_data_p$resale_price, 
     test_data_p$gwRF_pred)
```

### **Visualising the predicted values**

```{r}
ggplot(data = test_data_p,
       aes(x = GRF_pred,
           y = resale_price)) +
  geom_point()
```
