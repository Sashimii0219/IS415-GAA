[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 4 - Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to compute spatial weights using R through the following:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-loading-r-packages",
    "title": "Hands-on Exercise 4 - Spatial Weights and Applications",
    "section": "Installing and loading R packages",
    "text": "Installing and loading R packages\nThe R packages that we will be using today are spdep, sf, tmap and tidyverse.\n\n\nShow code\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data",
    "title": "Hands-on Exercise 4 - Spatial Weights and Applications",
    "section": "Importing Data",
    "text": "Importing Data\n\nDataset\nThe two datasets that we are using today: - Hunan county boundary layer, a geospatial data set in ESRI shapefile format. - Hunan_2012.csv, a csv file containing selected Hunan’s local development indicators in 2012.\n\n\nImport shapefile into r environment\nWe will use st_read() of sf package to import Hunan shapefile into R as a simple features Object of sf.\n\n\nShow code\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\n\nReading layer `Hunan' from data source \n  `/Users/jacksontan/Documents/Sashimii0219/IS415-GAA/Hands-on_Ex/Hands-on_Ex04/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nImport csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package as a R dataframe class.\n\n\nShow code\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\nPerforming relational join\nNow, we will update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe by using left_join() of dplyr package.\n\n\nShow code\nhunan &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-queen-contiguity-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-queen-contiguity-based-neighbours",
    "title": "Hands-on Exercise 4 - Spatial Weights and Applications",
    "section": "Computing (QUEEN) contiguity based neighbours",
    "text": "Computing (QUEEN) contiguity based neighbours\n\n\nShow code\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nMost connected region has 11 neighbors, 2 least connected region has 1 neighbor.\nwm_q lists all neighboring polygon (in this case of polygon 1).\n\n\nShow code\nwm_q[[1]]\n\n\n[1]  2  3  4 57 85\n\n\nRetrieving county name of Polygon 1 shows that it is “Anxiang”.\n\n\nShow code\nhunan$County[1]\n\n\n[1] \"Anxiang\"\n\n\nCounty name of the 5 neighboring polygons.\n\n\nShow code\nhunan$NAME_3[c(2,3,4,57,85)]\n\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nRetrieving GDPPC of these five countries.\n\n\nShow code\nc1 &lt;- wm_q[[1]]\nc1 &lt;- hunan$GDPPC[c1] # Filter GDPPC by the 5 polygons selected\nc1\n\n\n[1] 20981 34592 24473 21311 22879\n\n\nGDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\nComplete weight matrix:\n\n\nShow code\nstr(wm_q)\n\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-rook-contiguity-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-rook-contiguity-based-neighbours",
    "title": "Hands-on Exercise 4 - Spatial Weights and Applications",
    "section": "Computing (ROOK) contiguity based neighbours",
    "text": "Computing (ROOK) contiguity based neighbours\nWe will now compute Rook contiguity weight matrix\n\n\nShow code\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nDifference between Rook and Queen: The rook criterion defines neighbors by the existence of a common edge between two spatial units. The queen criterion is somewhat more encompassing and defines neighbors as spatial units sharing a common edge or a common vertex."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-contiguity-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-contiguity-weights",
    "title": "Hands-on Exercise 4 - Spatial Weights and Applications",
    "section": "Visualising contiguity weights",
    "text": "Visualising contiguity weights\nWe will now be visualising contiguity weights using a connectivity graph, which takes a point and displays a line to each neighboring point. To do this we will need to get points from the polygons, and the most typical method will be polygon centroids. We will first calculate these in the sf package.\n\nGetting Latitude and Longitude of Polygon Centroids\nTO get the points required to plot, we can’t simply just use st_centroids as we need the coordinates in a seperate data frame. To do this we will use a mapping function that applies a given function to each element of a vector and returns a vector of the same length. In this case, we will use the geometry column as input, st_centroid as the function, and map_dbl variation of map from purrr package.\n[[1]] retrieves only the longitude, whereas [[2]] retrieves the latitude.\n\n\nShow code\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\n\n\n\nShow code\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\n\nPutting them into the same object.\n\n\nShow code\ncoords &lt;- cbind(longitude, latitude)\n\n\nChecking the first few observations.\n\n\nShow code\nhead(coords)\n\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\nPlotting Queen contiguity based neighbours map\n\n\nShow code\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\nPlotting Rook contiguity based neighbours map\n\n\nShow code\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\nPlotting both Queen and Rook contiguity based neighbours maps\nFor easier comparison\n\n\nShow code\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#determine-the-cut-off-distance",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#determine-the-cut-off-distance",
    "title": "Hands-on Exercise 4 - Spatial Weights and Applications",
    "section": "Determine the cut-off distance",
    "text": "Determine the cut-off distance\nThe first step is to determine the upper limit for distance band, which can be done by the following steps: - Return a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep. - Convert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb(). - Return the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise. - Remove the list structure of the returned object by using unlist().\n\n\nShow code\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nSummary statistics shows that the largest first nearest neighbour distance is 61.79 km, which we will be using as upper limit."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-fixed-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-fixed-distance-weight-matrix",
    "title": "Hands-on Exercise 4 - Spatial Weights and Applications",
    "section": "Computing fixed distance weight matrix",
    "text": "Computing fixed distance weight matrix\n\n\nShow code\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE) # 62 is upper limit\nwm_d62\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nDisplaying the content of wm_d62 weight matrix:\n\n\nShow code\nstr(wm_d62)\n\n\nAnother way to display:\n\n\nShow code\ntable(hunan$County, card(wm_d62))\n\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nPlotting fixed distance weight matrix\n\n\nShow code\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\nRed line = 1st nearest neighbours Black lines = links of neighbours within the cut-off distance of 62km."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands-on Exercise 4 - Spatial Weights and Applications",
    "section": "Computing adaptive distance weight matrix",
    "text": "Computing adaptive distance weight matrix\nWhen computing fixed distance weight matrix, more densely settled areas tend to have more neighbours than less densely settled areas (urban vs rural). Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either by accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\n\nShow code\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nDisplaying content of the matrix\n\n\nShow code\nstr(knn6)\n\n\nIn this matrix, each country has exactly 6 neighbors.\n\nPlotting distance based neighbours\n\n\nShow code\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 4 - Spatial Weights and Applications",
    "section": "Row-standardised weights matrix",
    "text": "Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon.In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\n\nShow code\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.\nWeight of the first polygon’s eight neighbors type:\n\n\nShow code\nrswm_q$weights[10]\n\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbor has an equal weight of 0.125. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.125 before being tallied.\nRow standardised distance weight matrix\n\n\nShow code\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\n\nShow code\nrswm_ids$weights[1]\n\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\n\nShow code\nsummary(unlist(rswm_ids$weights))\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338 \n\n\n(To do further research on what this does)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-lag-with-row-standardized-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-lag-with-row-standardized-weights",
    "title": "Hands-on Exercise 4 - Spatial Weights and Applications",
    "section": "Spatial lag with row-standardized weights",
    "text": "Spatial lag with row-standardized weights\nspatially lagged values - average neighbor GDPPC value for each polygon\n\n\nShow code\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nGDPPC of the five countries retrieved in previous section\n\n\nShow code\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n\n[1] 20981 34592 24473 21311 22879\n\n\nShow code\n# mean of these adds up to first value of GDPPC.lag, as it should \n\n\nAppending the spatially lag GDPPC values onto hunan sf data frame\n\n\nShow code\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\n\nTable showing the average neighboring GDPPC values (stored in the lag GDPPC object) for each county.\n\n\nShow code\nhead(hunan)\n\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\n\nShow code\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-lag-as-a-sum-of-neighboring-values",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-lag-as-a-sum-of-neighboring-values",
    "title": "Hands-on Exercise 4 - Spatial Weights and Applications",
    "section": "Spatial lag as a sum of neighboring values",
    "text": "Spatial lag as a sum of neighboring values\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.\n\n\nShow code\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\n\nShow code\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\n\nExamining the results\n\n\nShow code\nlag_sum\n\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nNext, we will append the lag_sum GDPPC field into hunan sf data frame.\n\n\nShow code\nhunan &lt;- left_join(hunan, lag.res)\n\n\nPlotting both the GDPPC and Spatial Lag Sum GDPPC for comparison.\n\n\nShow code\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-window-average",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-window-average",
    "title": "Hands-on Exercise 4 - Spatial Weights and Applications",
    "section": "Spatial window average",
    "text": "Spatial window average\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\n\nShow code\nwm_qs &lt;- include.self(wm_q)\n\n\n\n\nShow code\nwm_qs[[1]]\n\n\n[1]  1  2  3  4 57 85\n\n\nPolygon [1] now has 6 neighbors (including self) instead of 5.\nNow we obtain weights with nb2listw()\n\n\nShow code\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nCreating the lag variable from our weight structure and GDPPC variable.\n\n\nShow code\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nConverting the lag variable listw object into a data.frame by using as.data.frame().\n\n\nShow code\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\n\nAppending lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\n\nShow code\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table.\n\n\nShow code\nhunan %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nUsing qtm() of tmap package to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\n\nShow code\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-window-sum",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-window-sum",
    "title": "Hands-on Exercise 4 - Spatial Weights and Applications",
    "section": "Spatial window sum",
    "text": "Spatial window sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nAdding the diagonal element to the neighbour list again\n\n\nShow code\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nAssigning binary weights to the neighbour structure that includes the diagonal element.\n\n\nShow code\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\n\nShow code\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nComputing the lag variable with lag.listw().\n\n\nShow code\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nConverting the lag variable listw object into a data.frame by using as.data.frame().\n\n\nShow code\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\n\nAppending w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\n\nShow code\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\n\nComparing the values of lag GDPPC and Spatial window average using kable() of Knitr package.\n\n\nShow code\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nUsing qtm() of tmap package to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\n\nShow code\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3 Part 1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "1. Learning Objectives\nSpatial Point Pattern Analysis is the evaluation of pattern/distribution of a set of points on a surface, where the points can be location of events (crime, traffic accident) or business services (chain outlets, hospitals).\nIn this Hands-on Exercise, we will be answering the following questions:\n\nAre the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?\n\n\n\n2. Getting Started\n\nInstalling and loading R packages\nThe R packages that I will be using today are sf, spatstat, raster, maptools and tmap.\n\nsf - Import, manage and process vector-based geospatial data in R.\n\n\n\nspatstat - Wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\n\n\n\nraster - reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\n\n\n\nmaptools - Provides a set of tools for manipulating geographic data. In this hands-on exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\n\n\n\ntmap - Provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\n\n\nShow code\n#install.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\npacman::p_load(maptools, sf, raster, spatstat, tmap, tidyverse)\n\n\n\n\n\nImporting Data\n\nDataset\nThe data that we will be using to create the choropleth map are: - Point feature data providing both location and attribute information of childcare centres downloaded from Data.gov.sg, in geojson format\n\n\nMaster Plan 2014 Subzone Boundary (Web) (Geospatial Data) downloaded from Data.gov.sg\n\n\n\nPolygon feature data showing the national boundary of Singapore, provided by SLA in ESRI shapefile format\n\n\n\nImporting Geospatial Data\nUsing st_read() function of sf package to import PreSchoolsLocation geojson file into R:\n\n\nShow code\nchildcare_sf &lt;- st_read(\"data/PreSchoolsLocation.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\n\nReading layer `PreSchoolsLocation' from data source \n  `/Users/jacksontan/Documents/Sashimii0219/IS415-GAA/Hands-on_Ex/Hands-on_Ex03/data/PreSchoolsLocation.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nCostalOutline files:\n\n\nShow code\nsg_sf &lt;- st_read(dsn = \"data/Coastal\", layer=\"CostalOutline\")\n\n\nReading layer `CostalOutline' from data source \n  `/Users/jacksontan/Documents/Sashimii0219/IS415-GAA/Hands-on_Ex/Hands-on_Ex03/data/Coastal' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nShow code\n# sg_sf &lt;- mpsz_sf %&gt;% st_union(), deriving from mpsz file\nglimpse(sg_sf)\n\n\nRows: 60\nColumns: 5\n$ GDO_GID    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ MSLINK     &lt;dbl&gt; 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19…\n$ MAPID      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ COSTAL_NAM &lt;chr&gt; \"Linkway\", \"SENTOSA\", \"PULAU SARIMBUN\", \"PULAU SAMULUN\", \"S…\n$ geometry   &lt;POLYGON [m]&gt; POLYGON ((14362.86 32307.49..., POLYGON ((25683.97 …\n\n\nOr deriving from MPSZ19.geojson file:\n\n\nShow code\nsg_sf2 &lt;- st_read(dsn = \"data/Coastal/MPSZ19.geojson\") %&gt;%  st_boundary() %&gt;% .['Name']\n\n\nReading layer `MPSZ19' from data source \n  `/Users/jacksontan/Documents/Sashimii0219/IS415-GAA/Hands-on_Ex/Hands-on_Ex03/data/Coastal/MPSZ19.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nShow code\nst_crs(sg_sf2) \n\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nMP14_SUBZONE_WEB_PL files:\n\n\nShow code\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")  %&gt;%\n  st_transform(crs = 3414)\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/jacksontan/Documents/Sashimii0219/IS415-GAA/Hands-on_Ex/Hands-on_Ex03/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nShow code\nst_crs(mpsz_sf) \n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nMapping the geospatial data\n\nPreviously…\nBy using what we learnt from previous hands-on exercise, we can use xxx to map out the locations for the childcare centres.\nAlternatively, we can also prepare a pin map by using tm_shape() with tm_dots().\nThe background can be changed, with 3 different internet map layers - ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap.\nReminder to change back to tmap_mode(‘plot’) after, as each interactive map consumes connection.\n\n\nShow code\ntmap_mode('plot')\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\nData Wrangling - sp’s Spatial Class\n\n\nConverting sf data frames to sp’s Spatial* class\n\n\nShow code\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\n\n\n\nConverting the Spatial* class into generic sp format\nAs spatstat requires the analytical data to be in ppp object form, we need to convert the Spatial classes* into Spatial object first as there is no direct way to convert a Spatial* classes into ppp object.\n\n\nShow code\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\n\n\n\nConverting the generic sp format into spatstat’s ppp format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\n\nShow code\nchildcare_ppp &lt;- as.ppp(childcare_sp)\n\n\nTL:DR: sf data frames -&gt; Spatial* class -&gt; generic sp format -&gt; spatstat’s ppp format\n\n\nShow code\nsummary(childcare_ppp)\n\n\nPlanar point pattern:  2290 points\nAverage intensity 2.875673e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units\n\n\nWhen we look at the summary statistics, we can see that there are duplicated points.\n\n\nHandling duplicated points\nChecking for any duplicates and the number of duplicates\n\n\nShow code\n# Check for any duplicates\nany(duplicated(childcare_ppp))\n\n\n[1] TRUE\n\n\nShow code\n# Count the number of duplicates\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n\n[1] 885\n\n\nBy plotting childcare data, we can see that the duplicated points are darker.\n\n\nShow code\ntmap_mode('view')\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\n\nTo overcome this problem there are 3 ways: 1. Delete duplicates, but some useful point events will be lost. 2. Jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space. 3. Make each point “Unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. By doing this, we will need analytical technique that takes into account these marks.\nWe will be using the jittering method.\n\n\nShow code\n# Jittering Approach\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\n\n\nCreating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nWe will now convert sg SpatialPolygon object into owin object of spatstat.\n\n\nShow code\nsg_owin &lt;- as(sg_sp, \"owin\")\n\n\n\n\nCombining point events object and owin object\nIn our last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the owin object.\n\n\nShow code\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\n\n\nShow code\nplot(childcareSG_ppp)\n\n\n\n\n\n\n\n\nFirst-order Spatial Point Patterns Analysis\nIn this section, we will perform first-order SPPA by using spatstat package. The hands-on exercise will focus on: - deriving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes, - performing Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics.\n\nKernel Density Estimation\nWe will be using density() of spatstat to calculate the kernel density estimation of childcare services in Singapore, with the following parameters: - bw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl(). - The smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”. - The intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nShow code\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nBandwidth used to compute the kde layer:\n\n\nShow code\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n\n   sigma \n281.8312 \n\n\nPlotting the kernel density.\n\n\nShow code\nplot(kde_childcareSG_bw)\n\n\n\n\n\nThe density values of the output range from 0 to 0.000035 which is way too small to comprehend. As the default unit of measurement of svy21 is in meter, the density value computed is in “number of points per square meter”. We will need to convert this from meter to kilometer.\n\nRescalling KDE values\nWe will use rescale() to convert the unit of measurement from meter to kilometer.\n\n\nShow code\nchildcareSG_ppp.km &lt;- rescale(childcareSG_ppp, 1000, \"km\")\n\n\nNow let’s re-run density() using the rescaled data and plot the kde map.\n\n\nShow code\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\nWorking with different automatic badwidth methods\nBeside bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth:\n\nbw.CvL()\n\n\n\nShow code\nbw.CvL(childcareSG_ppp.km)\n\n\n   sigma \n4.543278 \n\n\n\nbw.scott()\n\n\n\nShow code\nbw.scott(childcareSG_ppp.km)\n\n\n sigma.x  sigma.y \n2.111666 1.347496 \n\n\n\nbw.ppl()\n\n\n\nShow code\nbw.ppl(childcareSG_ppp.km)\n\n\n    sigma \n0.2109048 \n\n\nUse bw.ppl() to produce more appropriate value if pattern consists predominantly of tight clusters. If trying to detect single tight cluster in the midst of random noise then bw.diggle().\nComparing bw.ppl() AND bw.diggle()\n\n\nShow code\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\nWorking with different kernel methods\nThe default kernel method used in density.ppp() is gaussian, but there are 3 other options available, namely Epanechnikov, Quartic and Dics.\n\n\nShow code\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\n\n\n\n\n\n\n\nFixed and Adaptive KDE\n\nComputing KDE by using fixed bandwidth\nNow we will compute a KDE layer by defining a bandwidth of 600m. In the code chunk, 0.6 = 600m as unit of measurement used is km.\n\n\nShow code\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\nComputing KDE by using adaptive bandwidth\nCons of fixed bandwidth - very sensitive to highly skewed distribution of spatial point patterns over geographical units, e.g. urban vs rural. In such cases, we use adaptive bandwidth.\nDeriving adaptive kernel density using density.adaptive() of spatstat package.\n\n\nShow code\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\nComparing the fixed and adaptive kernel density estimation outputs:\n\n\nShow code\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\nConverting KDE output into grid object\nConverting results so that it is suitable for mapping purposes.\n\n\nShow code\ngridded_kde_childcareSG_bw &lt;- as.SpatialGridDataFrame.im(kde_childcareSG.bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\nConverting gridded output into raster\nNext, we will convert the gridded kernal density objects into RasterLayer object by using raster() of raster package.\nDefinition: A raster layer is any other type of layer that consists of pixels — images, masks, paintings, and photos — so when you paint or edit images, you’re working with raster layers. A raster layer (or bitmap) is made up of pixels which are, essentially, points of color placed within a rectangular grid.\n\n\nShow code\nkde_childcareSG_bw_raster &lt;- raster(gridded_kde_childcareSG_bw)\n\n\nNow if we look at the properties of kde_childcareSG_bw_raster layer, we can see that the crs property is NA.\n\n\nShow code\nkde_childcareSG_bw_raster\n\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -1.233003e-14, 41.20628  (min, max)\n\n\n\n\nAssigning projection systems\nWe will then assign the CRS information on this layer.\n\n\nShow code\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -1.233003e-14, 41.20628  (min, max)\n\n\n\n\n\nVisualising the output in tmap\nNow, on to displaying the raster layer in cartographic quality map using tmap package.\n\n\nShow code\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\nComparing Spatial Point Patterns using KDE\nIn the next section, we will be comparing the KDE of childcare at Punggol, Tampines, Choa Chu Kang, and Jurong West planning areas.\n\nExtracting study area\nWe first extract the target planning areas.\n\n\nShow code\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\n\nPlotting these target areas\n\n\nShow code\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\nplot(tm, main = \"Tampines\")\nplot(ck, main = \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n\nConverting the spatial point data frame into generic sp format\nSpatialPolygonsDataFrame layers -&gt; generic spatialpolygons layers.\n\n\nShow code\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\n\n\n\nCreating owin object\nConverting to owin object required by spatstat.\n\n\nShow code\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\n\n\n\nCombining childcare points and the study area\nFirst we extract childcare that are within the specific regions for later use.\n\n\nShow code\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\n\nNext, rescale() function to transform the unit of measurement from metre to kilometre.\n\n\nShow code\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\n\nNow let’s plot these planning areas and the locations of their respective childcare centres.\n\n\nShow code\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\", size = 0.3)\nplot(childcare_tm_ppp.km, main=\"Tampines\", size = 0.3)\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\", size = 0.3)\nplot(childcare_jw_ppp.km, main=\"Jurong West\", size = 0.3)\n\n\n\n\n\n\n\n\nComputing KDE\nNow onto the main objective - computing the KDE of these four planning area (using bw.diggle method).\n\n\nShow code\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\n\n\n\n\nNow with fixed bandwidth KDE\n\n\nShow code\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\n\n\n\n\n\n\n\nNearest Neighbour Analysis\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat package.\nUsing 95% confidence interval, the test hypotheses are:\nHo = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\n\n\nShow code\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.40435, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nAs p-value &lt; 0.05, we reject Ho, which means that the distribution of childcare services in singapore are not randomly distributed.\n\n\nChoa Chu Kang\n\n\nShow code\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.79126, p-value = 0.0001651\nalternative hypothesis: two-sided\n\n\n\n\nTampines\n\n\nShow code\nclarkevans.test(childcare_pg_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_pg_ppp\nR = 0.76354, p-value = 4.678e-05\nalternative hypothesis: two-sided\n\n\nConclusion: The distribution of childcare services in the regions we tested are not randomly distributed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html",
    "title": "Hands-on Exercise 3 Part 2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Network constrained Spatial Point Patterns Analysis (NetSPAA) is a collection of spatial point patterns analysis methods special developed for analysing spatial point event occurs on or alongside network. The spatial point event can be locations of traffic accident or childcare centre for example. The network, on the other hand can be a road network or river network.\nIn this hands-on exercise, we are going to gain hands-on experience on using appropriate functions of spNetwork package:\n\nto derive network constrained kernel density estimation (NetKDE), and\nto perform network G-function and k-function analysis"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#installing-and-loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#installing-and-loading-r-packages",
    "title": "Hands-on Exercise 3 Part 2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Installing and loading R packages",
    "text": "Installing and loading R packages\nThe R packages that we will be using today are sf, spatstat, raster, maptools and tmap.\n\nspNetwork - which provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It also can be used to build spatial matrices (‘listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\n\n\n\nrgdal - which provides bindings to the ‘Geospatial’ Data Abstraction Library (GDAL) (&gt;= 1.11.4) and access to projection/transformation operations from the PROJ library. In this exercise, rgdal will be used to import geospatial data in R and store as sp objects.\n\n\n\nsp - which provides classes and methods for dealing with spatial data in R. In this exercise, it will be used to manage SpatialPointsDataFrame and SpatiaLinesDataFrame, and for performing projection transformation.\n\n\n\nsf - Import, manage and process vector-based geospatial data in R.\n\n\n\ntmap - Provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\n\n\nShow code\n#install.packages(\"rgdal\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\n\n\nShow code\npacman::p_load(sp, sf, rgdal, spNetwork, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#importing-data",
    "title": "Hands-on Exercise 3 Part 2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Importing Data",
    "text": "Importing Data\n\nDataset\nWe will be analysing the spatial distribution of childcare centre in Punggol planning area using the following two geospatial data sets:\n\n\nPunggol_St, a line features geospatial data which store the road network within Punggol Planning Area.\n\n\n\nPunggol_CC, a point feature geospatial data which store the location of childcare centres within Punggol Planning Area.\n\n\n\nImporting Geospatial Data\nWe will use st_read() of sf package to important Punggol_St and Punggol_CC geospatial data sets into RStudio as sf data frames.\n\n\nShow code\nnetwork &lt;- st_read(dsn=\"data\", \n                   layer=\"Punggol_St\")\n\n\nReading layer `Punggol_St' from data source \n  `/Users/jacksontan/Documents/Sashimii0219/IS415-GAA/Hands-on_Ex/Hands-on_Ex03/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\n\n\nShow code\nchildcare &lt;- st_read(dsn=\"data\",\n                     layer=\"Punggol_CC\")\n\n\nReading layer `Punggol_CC' from data source \n  `/Users/jacksontan/Documents/Sashimii0219/IS415-GAA/Hands-on_Ex/Hands-on_Ex03/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\n\n\nShow code\nstr(network)\n\n\nClasses 'sf' and 'data.frame':  2642 obs. of  3 variables:\n $ LINK_ID : num  1.16e+08 1.16e+08 1.16e+08 1.16e+08 1.16e+08 ...\n $ ST_NAME : chr  \"PUNGGOL RD\" \"PONGGOL TWENTY-FOURTH AVE\" \"PONGGOL SEVENTEENTH AVE\" \"PONGGOL SEVENTEENTH AVE\" ...\n $ geometry:sfc_LINESTRING of length 2642; first list element:  'XY' num [1:2, 1:2] 36547 36559 44575 44614\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA\n  ..- attr(*, \"names\")= chr [1:2] \"LINK_ID\" \"ST_NAME\"\n\n\nShow code\nstr(childcare)\n\n\nClasses 'sf' and 'data.frame':  61 obs. of  2 variables:\n $ Name    : chr  \"kml_10\" \"kml_99\" \"kml_100\" \"kml_101\" ...\n $ geometry:sfc_POINT of length 61; first list element:  'XYZ' num  36174 42550 0\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA\n  ..- attr(*, \"names\")= chr \"Name\"\n\n\nWe use spTransform() of sp package to assign EPSG code to the SpatialDataFrames. The epsg:3414 is the code for svy21.\n\n\nShow code\nchildcare &lt;- st_transform(childcare, crs = 3414)\nnetwork &lt;- st_transform(network, crs = 3414)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#preparing-the-lixels-objects",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#preparing-the-lixels-objects",
    "title": "Hands-on Exercise 3 Part 2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Preparing the lixels objects",
    "text": "Preparing the lixels objects\nBefore we can compute NetKDE, the SpatialLines object need to be cut into lixels with a specified minimal distance, and this can be done using lixelize_lines() of spNetwork package.\n\n\nShow code\nlixels &lt;- lixelize_lines(network, \n                         700, \n                         mindist = 350)\n\n\nNOTE: After cut, if the length of the final lixel is shorter than the minimum distance, then it is added to the previous lixel. If NULL, then mindist = maxdist/10. Also note that the segments that are already shorter than the minimum distance are not modified"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#generating-line-centre-points",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#generating-line-centre-points",
    "title": "Hands-on Exercise 3 Part 2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Generating line centre points",
    "text": "Generating line centre points\nNext, we will use lines_center() of spNetwork to generate a SpatialPointsDataFrame (i.e. samples) with line centre points.\n\n\nShow code\nsamples &lt;- lines_center(lixels)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#computing-netkde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html#computing-netkde",
    "title": "Hands-on Exercise 3 Part 2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Computing NetKDE",
    "text": "Computing NetKDE\n\n\nShow code\ndensities &lt;- nkde(network, \n                  events = childcare,\n                  w = rep(1,nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\", # kernel method\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  # method used to calculate NKDE. spNetwork supports 3 popular methods, namely simple, discontinuous, and continuous\n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, #we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\nVisualising NetKDE\nBefore computing, we need to insert the computed values back into samples and lixels objects as density field.\n\n\nShow code\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\n\nSince svy21 projection system is in meter, the computed density values are very small i.e. 0.0000005. We will thus need to rescale the density values from number of events per meter to number of events per kilometer.\n\n\nShow code\n# rescaling to help the mapping\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\n\n\n\nShow code\ntmap_mode('view')\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\n\n\n\nShow code\ntmap_mode('plot')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "In this chapter, we will learn how to plot functional and truthful choropleth maps by using an R package called tmap."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#context",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#context",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "2.1 Context",
    "text": "2.1 Context\nIn general, thematic mapping involves the use of map symbols to visualize selected properties of geographic features that are not naturally visible, such as population, temperature, crime rate, and property prices, just to mention a few of them.\nGeovisualisation, on the other hand, works by providing graphical ideation to render a place, a phenomenon or a process visible, enabling human’s most powerful information-processing abilities – those of spatial cognition associated with our eye–brain vision system – to be directly brought to bear."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#loading-r-packages",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "2.2 Loading R Packages",
    "text": "2.2 Loading R Packages\nThe R packages that we will be using today are tmap, readr, tidyr, dplyr and sf.\n\n\nShow code\npacman::p_load(tmap, tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-importing",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-importing",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "2.3 Data Importing",
    "text": "2.3 Data Importing\n\n2.3.1 Dataset\nThe data that we will be using to create the choropleth map are:\n\nMaster Plan 2014 Subzone Boundary (Web) (Geospatial Data)\n\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in CSV (Aspatial Data)\n\nNote: Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n2.3.2 Importing Geospatial Data\nUsing st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R.\n\n\nShow code\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/jacksontan/Documents/Sashimii0219/IS415-GAA/Hands-on_Ex/Hands-on_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n2.3.3 Importing Attribute Data\nImporting respopagesextod2011to2020.csv using read_csv() function of readr package into R.\n\n\nShow code\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nShow code\npopdata\n\n\n# A tibble: 984,656 × 7\n   PA         SZ                     AG     Sex     TOD                Pop  Time\n   &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;\n 1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 1- and 2-Ro…     0  2011\n 2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 3-Room Flats    10  2011\n 3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 4-Room Flats    30  2011\n 4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 5-Room and …    50  2011\n 5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HUDC Flats (exc…     0  2011\n 6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Landed Properti…     0  2011\n 7 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Condominiums an…    40  2011\n 8 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Others               0  2011\n 9 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 1- and 2-Ro…     0  2011\n10 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 3-Room Flats    10  2011\n# ℹ 984,646 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-preparation",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "2.4 Data Preparation",
    "text": "2.4 Data Preparation\n\n2.4.1 Data Wrangling\nWe will be preparing a data table with year 2020 values that includes the following variables:\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25 to 29 until age group 60 to 64,\nAGED: age group 65 and above, - TOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\nUsing the following functions: - pivot_wider() of tidyr package, and - mutate(), filter(), group_by() and select() of dplyr package.\n\n\nShow code\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;% # Only select year 2020 values\n  group_by(PA, SZ, AG) %&gt;% # Group data by the following variables\n  summarise(`POP` = sum(`Pop`)) %&gt;% # Group Pop value by summing them\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;% \n  # Splitting the values in column AG into their own column, with the value from POP\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`) # Calculate %\n/`ECONOMY ACTIVE`) %&gt;%\n  dplyr::select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\nShow code\npopdata2020\n\n\n# A tibble: 332 × 7\n   PA         SZ                   YOUNG `ECONOMY ACTIVE`  AGED TOTAL DEPENDENCY\n   &lt;chr&gt;      &lt;chr&gt;                &lt;dbl&gt;            &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1 Ang Mo Kio Ang Mo Kio Town Cen…  1440             2610   760  4810      0.843\n 2 Ang Mo Kio Cheng San             6640            15460  6050 28150      0.821\n 3 Ang Mo Kio Chong Boon            6150            13950  6470 26570      0.905\n 4 Ang Mo Kio Kebun Bahru           5540            12090  5120 22750      0.882\n 5 Ang Mo Kio Sembawang Hills       2100             3410  1310  6820      1    \n 6 Ang Mo Kio Shangri-La            3960             8420  3610 15990      0.899\n 7 Ang Mo Kio Tagore                2220             4200  1530  7950      0.893\n 8 Ang Mo Kio Townsville            4690            11450  5100 21240      0.855\n 9 Ang Mo Kio Yio Chu Kang             0                0     0     0    NaN    \n10 Ang Mo Kio Yio Chu Kang East     1220             2300   750  4270      0.857\n# ℹ 322 more rows\n\n\nThe values in the PA and SZ fields consist of both upper and lowercase values. We will standardize them all by converting them all to uppercase.\n\n\nShow code\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0) # Filter out areas with no \"ECONOMY ACTIVE\"\n\n\n\n\n2.4.2 Relational Join\nUsing the left_join() of dplyr, we join the geographical data and the attribute table using planning subzone name (SUBZONE_N of mpsz is = SZ of popdata2020).\n\n\nShow code\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\n\n\nShow code\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-a-choropleth-map-quickly-by-using-qtm",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-a-choropleth-map-quickly-by-using-qtm",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "3.1 Plotting a choropleth map quickly by using qtm()",
    "text": "3.1 Plotting a choropleth map quickly by using qtm()\nEasiest and quickest to draw a choropleth map using tmap is using qtm().\n\ntmap_mode(\"plot\") creates a static map, whereas “view” creates an interactive map.\nfill argument is used to map the attribute.\n\n\n\nShow code\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "3.2 Creating a choropleth map by using tmap’s elements",
    "text": "3.2 Creating a choropleth map by using tmap’s elements\nDisadvantage of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map, tmap’s drawing elements should be used.\n\n\nShow code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\nThe map above consist of the following elements:\n\n3.2.1 Base Map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\n\n3.2.2 Using tm_polygons()\n\n\nShow code\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\nNote:\n\nDefault interval binning used - “pretty”\nDefault colour scheme - “YlOrRd”\nDefault Missing value colour - Grey\n\n\n\n3.2.3 Using tm_fill() and tm_borders()\ntm_polygons() can be further broken down into:\n\ntm_fill() - shades the polygon.\ntm_borders() - adds the borders of the shapefile onto the choropleth map.\n\n\n\nShow code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n4 arguments for tm_borders():\n\nalpha = transparency number between 0 and 1,\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-methods-of-tmap",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "3.3 Data classification methods of tmap",
    "text": "3.3 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define data classfication method, we will be using the style argument of of tm_fill() or tm_polygons().\n\n3.3.1 Plotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\n\nShow code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n3.3.2 Plotting choropleth map with custom break\nFor all the built-in styles, the category breaks are computed internally. This can be overriden using the breaks argument of the tm_fill() function. In order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nIt is a good practice to get some descriptive statistics on the variable before setting the break points.\n\n\nShow code\nsummary(mpsz_pop2020$DEPENDENCY)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00).\nPlotting the map using the breakpoints:\n\n\nShow code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#colour-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#colour-scheme",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "3.4 Colour Scheme",
    "text": "3.4 Colour Scheme\n\n3.4.1 Using ColourBrewer palette\nAssigning a colour to palette argument of tm_fill() changes the colour.\n\n\nShow code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nTo reverse the colour shading, add a “-” prefix.\n\n\nShow code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#map-layout",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#map-layout",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "3.5 Map layout",
    "text": "3.5 Map layout\nRefers to the combination of all map elements into a cohesive map, e.g. the title, the scale bar, the compass, margins and aspects ratios.\n\n3.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\n\nShow code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n3.5.2 Map Style\nRefers to the layout settings.\n\n\nShow code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n3.5.3 Cartographic Furniture\nRefers to map furniture like compass, scale bar and grid lines.\n\n\nShow code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) + # Compass\n  tm_scale_bar(width = 0.15) + # Scale Bar\n  tm_grid(lwd = 0.1, alpha = 0.2) + # Grid line\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\nTo reset to default style, use tmap_style(“white”)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#drawing-small-multiple-choropleth-maps",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#drawing-small-multiple-choropleth-maps",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "3.6 Drawing Small Multiple Choropleth Maps",
    "text": "3.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps / facet maps are composed of many maps arrange side-by-side / stacked vertically. It is used to visualise how spatial relationships change with respect to another variable, such as time. This can be done using tmap in 3 ways:\n\n3.6.1 By assigning multiple values to at least one of the asthetic arguments\nSmall multiple choropleth maps are created by defining ncols in tm_fill(), in this case c(“YOUNG”, “AGED”).\n\n\nShow code\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\nSmall multiple choropleth maps can also be created by assigning multiple values to at least one of the aesthetic arguments.\n\n\nShow code\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n3.6.2 By defining a group-by variable in tm_facets(), and\n\n\nShow code\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", # here\n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n3.6.3 By creating multiple stand-alone maps with tmap_arrange().\n\n\nShow code\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2) # here"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#mappping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#mappping-spatial-object-meeting-a-selection-criterion",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "3.7 Mappping Spatial Object Meeting a Selection Criterion",
    "text": "3.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection function to map spatial objects meeting the selection criterion.\n\n\nShow code\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, we will be learning the following:\n\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics.\ncompute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions spdep package;\ncompute Getis-Ord’s Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of spdep package; and\nto visualise the analysis output by using tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#context",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#context",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "2.1 Context",
    "text": "2.1 Context\nIn spatial policy, one of the main development objective of the local govenment and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#loading-r-packages",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "2.2 Loading R Packages",
    "text": "2.2 Loading R Packages\nThe R packages that we will be using today are:\n\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\n\n\nShow code\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-importing-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-importing-and-preparation",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "2.3 Data Importing and Preparation",
    "text": "2.3 Data Importing and Preparation\n\n2.3.1 Dataset\nWe will be using the following dataset in this hands-on exercise:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n2.3.2 Importing Data\nWe will use st_read() of sf package to import Hunan shapefile into R as a simple feature object.\n\n\nShow code\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\n\nReading layer `Hunan' from data source \n  `/Users/jacksontan/Documents/Sashimii0219/IS415-GAA/Hands-on_Ex/Hands-on_Ex05/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package as a R data frame class.\n\n\nShow code\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\n2.3.3 Relational Join\nWe will perform a left_join() from dplyr package to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe.\n\n\nShow code\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\n\n\n\n2.3.4 Visualising Regional Development Indicator\nBefore we begin our analysis, it is always good to visualise our geographical data. We will now explore the distribution of GDPPC 2012 by using functions of tmap package to prepare a basemap and a choropleth map.\n\n\nShow code\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "3.1 Computing Contiguity Spatial Weights",
    "text": "3.1 Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nThe poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. More specifically, as done in previous hands-on exercise, we will be computing Queen contiguity weight matrix.\n\n\nShow code\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "3.2 Row-standardised weights matrix",
    "text": "3.2 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\n\nShow code\nrswm_q &lt;- nb2listw(wm_q, # must be an object of nb class\n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nNote:\n\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#morans-i-test",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#morans-i-test",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "4.1 Moran’s I test",
    "text": "4.1 Moran’s I test\n\n\nShow code\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nStatistical Conclusion:\n\nMoran I &gt; 0 indicates positive spatial autocorrelation (similar values cluster together),\nMoran I &lt; 0 indicates negative spatial autocorrelation (dissimilar values cluster together),\nMoran I = 0 indicates no spatial autocorrelation (random distribution).\n\n\nIn our case, the Moran I statistic is 0.300749970, which is positive, suggesting the presence of positive spatial autocorrelation.\nThe Moran I statistic standard deviate is 4.7351, indicating a significant result.\nThe p-value is very small (1.095e-06), further supporting the rejection of the null hypothesis that there is no spatial autocorrelation.\n\nIn summary, based on these results, we can conclude that there is a significant positive spatial autocorrelation in the variable GDPPC, meaning that similar values tend to be clustered together in space."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-monte-carlo-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-monte-carlo-morans-i",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "4.2 Computing Monte Carlo Moran’s I",
    "text": "4.2 Computing Monte Carlo Moran’s I\nWe will now be performing permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed.\n\n\nShow code\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nIn conclusion, based on the Monte Carlo simulation results, you can affirm the presence of significant positive spatial autocorrelation in the variable GDPPC. The small p-value supports the rejection of the null hypothesis, indicating that the observed spatial pattern is unlikely to be due to random chance."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-monte-carlo-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-monte-carlo-morans-i",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "4.3 Visualising Monte Carlo Moran’s I",
    "text": "4.3 Visualising Monte Carlo Moran’s I\nLet us us examine the simulated Moran’s I test statistics in greater detail by plotting the distribution of the statistical values as a histogram. We will be using hist() and abline() of R Graphics.\n\n\nShow code\nmean(bperm$res[1:999])\n\n\n[1] -0.01504572\n\n\n\n\nShow code\nvar(bperm$res[1:999])\n\n\n[1] 0.004371574\n\n\n\n\nShow code\nsummary(bperm$res[1:999])\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\n\nShow code\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#gearys-c-test",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#gearys-c-test",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "5.1 Geary’s C test",
    "text": "5.1 Geary’s C test\nWe can perform the Geary’s C test for spatial autocorrelation by using geary.test() of spdep.x`\n\n\nShow code\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\nStatistical Conclusion:\n\nThe Geary C statistic ranges from 0 to 2. A value less than 1 suggests positive spatial autocorrelation, while a value greater than 1 suggests negative spatial autocorrelation. In your case, the value is less than 1 (0.6907223), indicating positive spatial autocorrelation.\n\nBased on these results, we can conclude that there is significant positive spatial autocorrelation in the variable GDPPC. The low p-value and the observed Geary C statistic being less than 1 provide evidence against the null hypothesis of no spatial autocorrelation, supporting the presence of a positive spatial pattern in the data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-monte-carlo-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-monte-carlo-gearys-c",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "5.2 Computing Monte Carlo Geary’s C",
    "text": "5.2 Computing Monte Carlo Geary’s C\nWe will now be performing permutation test for Geary’s C statistic by using geary.mc() of spdep. A total of 1000 simulation will be performed.\n\n\nShow code\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nIn summary, based on the Monte Carlo simulation results:\n\nThe observed Geary C statistic is significantly different from what would be expected under the null hypothesis of no spatial autocorrelation.\nThe small p-value indicates strong evidence against the null hypothesis.\nThe alternative hypothesis of positive spatial autocorrelation is supported.\n\nTherefore, we can conclude that there is significant positive spatial autocorrelation in the variable GDPPC based on both the observed Geary C statistic and the Monte Carlo simulation results."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-monte-carlo-morans-i-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-monte-carlo-morans-i-1",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "5.3 Visualising Monte Carlo Moran’s I",
    "text": "5.3 Visualising Monte Carlo Moran’s I\nNext, we will plot a histogram to reveal the distribution of the simulated values.\n\n\nShow code\nmean(bperm$res[1:999])\n\n\n[1] 1.004402\n\n\n\n\nShow code\nvar(bperm$res[1:999])\n\n\n[1] 0.007436493\n\n\n\n\nShow code\nsummary(bperm$res[1:999])\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\n\nShow code\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-morans-i-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-morans-i-correlogram",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "6.1 Computing Moran’s I correlogram",
    "text": "6.1 Computing Moran’s I correlogram\nWe will be using sp.correlogram() of spdep package to compute a 6-lag spatial correlogram of GDPPC using the global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\n\nShow code\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\nPlotting the output alone might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\n\nShow code\nprint(MI_corr)\n\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOverall, the results suggest significant positive spatial autocorrelation in hunan$GDPPC across various distance lags, supporting the conclusion that neighboring areas tend to exhibit similar economic characteristics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-gearys-c-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-gearys-c-correlogram",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "6.2 Computing Geary’s C correlogram",
    "text": "6.2 Computing Geary’s C correlogram\nWe will be using sp.correlogram() of spdep package to compute a 6-lag spatial correlogram of GDPPC using the global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\n\nShow code\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\nSimilar to the previous step, we will print out the analysis report.\n\n\nShow code\nprint(GC_corr)\n\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn conclusion, the interpretation is that there is significant positive spatial autocorrelation in hunan$GDPPC, and the significance varies across different distance lags. Areas with similar economic characteristics are spatially clustered, especially at certain lag distances."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-local-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-local-morans-i",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "7.1 Computing local Moran’s I",
    "text": "7.1 Computing local Moran’s I\nWe will be using the localmoran() function of spdep to compute local Moran’s I. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\n\n7.1.1 Computing local Moran’s I of GDPPC2012 at the county level.\n\n\nShow code\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\nListing the content of the local Moran matrix derived by using printCoefmat().\n\n\nShow code\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n\n7.1.2 Mapping the local Moran’s I\nBefore mapping the local Moran’s I map, we will append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame.\n\n\nShow code\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\nWe will now plot the local Moran’s I values using choropleth mapping functions of tmap package.\n\n\nShow code\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n7.1.3 Mapping local Moran’s I p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values.\nWe will now plot a choropleth map of Moran’s I p-values by using functions of tmap package.\n\n\nShow code\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\n\n\nShow code\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-moran-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-moran-scatterplot",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "8.1 Plotting Moran scatterplot",
    "text": "8.1 Plotting Moran scatterplot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nWe will now plot a Moran scatterplot of GDPPC 2012 by using moran.plot() of the spdep package.\n\n\nShow code\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\nNotice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. This are the high-high locations in the lesson slide."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-moran-scatterplot-with-standardised-variable",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-moran-scatterplot-with-standardised-variable",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "8.2 Plotting Moran scatterplot with standardised variable",
    "text": "8.2 Plotting Moran scatterplot with standardised variable\nFirst we will use scale() to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) from the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\n\nShow code\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.\nNow, we are ready to plot the Moran scatterplot again.\n\n\nShow code\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#preparing-lisa-map-classes",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#preparing-lisa-map-classes",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "8.3 Preparing LISA map classes",
    "text": "8.3 Preparing LISA map classes\nHere are the steps to prepare a LISA cluster map.\n\n\nShow code\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\n\nNext, derives the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.\n\n\nShow code\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)\n\n\nFollowed by centering the local Moran’s around the mean.\n\n\nShow code\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\n\nNext, we will set a statistical significance level for the local Moran. In this case we set it to 0.05.\n\n\nShow code\nsignif &lt;- 0.05       \n\n\nThese four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.\n\n\nShow code\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4\n\n\nLastly, places non-significant Moran in the category 0.\n\n\nShow code\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\n\nThis is how it will look like, if we combine them into a single code chunk.\n\n\nShow code\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I &lt;- localMI[,1]   \nsignif &lt;- 0.05       \nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4    \nquadrant[localMI[,5]&gt;signif] &lt;- 0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-lisa-map",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-lisa-map",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "8.4 Plotting LISA map",
    "text": "8.4 Plotting LISA map\nNow, we are ready to build the LISA map!\n\n\nShow code\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its LISA map next to each other.\n\n\nShow code\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getis-and-ords-g-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getis-and-ords-g-statistics",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "9.1 Getis and Ord’s G-Statistics",
    "text": "9.1 Getis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#step-1-deriving-spatial-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#step-1-deriving-spatial-weight-matrix",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "9.2 Step 1: Deriving spatial weight matrix",
    "text": "9.2 Step 1: Deriving spatial weight matrix\n\n9.2.1 Deriving distance-based weight matrix\nFirst, we need to define a new set of neighbours. Whi;st the spatial autocorrelation considers units with shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\n9.2.1.1 Deriving the centroid\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid(). We will be using map_dbl variation of map from the purrr package.\nTo get our longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\n\nShow code\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\n\nShow code\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\n\nShow code\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n\n9.2.1.2 Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n\nShow code\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n9.2.1.3 Computing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\n\nShow code\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\n\nShow code\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\n\n9.2.2 Computing adaptive distance weight matrix\nne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as seen below.\n\n\nShow code\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, we convert the nb object into spatial weights object using nb2listw().\n\n\nShow code\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#step-2-computing-gi-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#step-2-computing-gi-statistics",
    "title": "Hands-on Exercise 5 - Global and Local Measures of Spatial Autocorrelation",
    "section": "9.3 Step 2: Computing Gi statistics",
    "text": "9.3 Step 2: Computing Gi statistics\n\n9.3.1 Gi statistics using fixed distance\n\n\nShow code\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan sf data frame.\n\n\nShow code\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\n\nThe code chunk above performs 3 tasks:\n\nConverts the output vector (i.e. gi.fixed) into r matrix object by using as.matrix().\ncbind() is used to join hunan@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi.\nField name of the gi values is renamed to gstat_fixed by using rename().\n\n\n\n9.3.2 Mapping Gi values with fixed distance weights\nWe will now use relevant functions below to map the Gi values derived using fixed distance weight matrix.\n\n\nShow code\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\n\n\n\n\nThe intensity of color in different areas of the map reflects the strength of the clustering. Darker or more intense colors often indicate stronger clustering.\n\n\n9.3.3 Gi statistics using adaptive distance\nWe will now compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\n\nShow code\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n\n9.3.4 Mapping Gi values with adaptive distance weights\nWe will now use relevant functions below to map the Gi values derived using adaptive distance weight matrix.\n\n\nShow code\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "By the end of this hands-on exercise, we should be able to do the following:\n\ninstalling and loading sf and tidyverse packages into R environment,\nimporting geospatial data by using appropriate functions of sf package,\nimporting aspatial data by using appropriate function of readr package,\nexploring the content of simple feature data frame by using appropriate Base R and sf functions,\nassigning or transforming coordinate systems by using using appropriate sf functions,\nconverting an aspatial data into a sf data frame by using appropriate function of sf package,\nperforming geoprocessing tasks by using appropriate functions of sf package,\nperforming data wrangling tasks by using appropriate functions of dplyr package and\nperforming Exploratory Data Analysis (EDA) by using appropriate functions from ggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#context",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#context",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "2.1 Context",
    "text": "2.1 Context\nData are key to data analytics including geospatial analytics. Hence, before analysing, we need to assemble the necessary data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#loading-r-packages",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "2.2 Loading R Packages",
    "text": "2.2 Loading R Packages\nIn this section, we will be installing and loading tidyverse and sf packages.\n\n\nShow code\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#data-importing-and-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#data-importing-and-preparation",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "2.3 Data Importing and Preparation",
    "text": "2.3 Data Importing and Preparation\nNext, we will be importing the geospatial data files.\n\n2.3.1 Importing Master Plan 2014 Subzone Boundary (Web) files:\n\n\nShow code\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/jacksontan/Documents/Sashimii0219/IS415-GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n2.3.2 Importing LTA Cycling Path files:\n\n\nShow code\ncyclingpath = st_read(dsn = \"data/geospatial\",\n                      layer = \"CyclingPathGazette\")\n\n\nReading layer `CyclingPathGazette' from data source \n  `/Users/jacksontan/Documents/Sashimii0219/IS415-GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n2.3.3 Importing Preschools Location KML file files:\n\n\nShow code\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/jacksontan/Documents/Sashimii0219/IS415-GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-st_geometry",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-st_geometry",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "3.1 Working with st_geometry()",
    "text": "3.1 Working with st_geometry()\nThis code displays the basic feature information.\n\n\nShow code\nst_geometry(mpsz)\n\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-glimpse",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-glimpse",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "3.2 Working with glimpse()",
    "text": "3.2 Working with glimpse()\nThis code reveals data type of each fields, and a glimpse of the data.\n\n\nShow code\nglimpse(mpsz)\n\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-head",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-head",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "3.3 Working with head()",
    "text": "3.3 Working with head()\nThis code reveals complete info of a feature object.\n\n\nShow code\nhead(mpsz, n=5)\n\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#simple-visualisation",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#simple-visualisation",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "4.1 Simple visualisation",
    "text": "4.1 Simple visualisation\n\n\nShow code\nplot(mpsz)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-only-the-geometry",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-only-the-geometry",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "4.2 Plotting only the geometry",
    "text": "4.2 Plotting only the geometry\n\n\nShow code\nplot(st_geometry(mpsz))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-using-specific-attribute",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-using-specific-attribute",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "4.3 Plotting using specific attribute",
    "text": "4.3 Plotting using specific attribute\n\n\nShow code\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "5.1 Assigning EPSG code to a simple feature data frame",
    "text": "5.1 Assigning EPSG code to a simple feature data frame\n\n\nShow code\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\n\nChecking that it is now 3414 (svy21):\n\n\nShow code\nst_crs(mpsz3414)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "5.2 Transforming the projection of preschool from wgs84 to svy21",
    "text": "5.2 Transforming the projection of preschool from wgs84 to svy21\nWhen we need to reproject one coordinate system to another coordinate system mathematically, we will use st_transform() instead of st_set_crs().\nNote: In practice, we need find out the appropriate project coordinate system to use before performing the projection transformation.\n\n\nShow code\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-aspatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "6.1 Importing the Aspatial Data",
    "text": "6.1 Importing the Aspatial Data\nImporting the file\n\n\nShow code\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\n\nExamining the data file to ensure it has been imported correctly. The fields that we will be using is the latitude and longitude column, which corresponds to the x and y coordinate.\n\n\nShow code\nlist(listings)\n\n\n[[1]]\n# A tibble: 3,457 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,447 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "6.2 Creating a simple feature data frame from an aspatial data frame",
    "text": "6.2 Creating a simple feature data frame from an aspatial data frame\nNow we will create a simple feature data frame from an aspatial data frame using st_as_sf() of sf packages.\n\n\nShow code\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\n\nThings to note:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\nNow if we use glimpse() on the newly created simple feature data frame, we can see that the longitude and latitude columns have been dropped, replaced by a new column called geometry.\n\n\nShow code\nglimpse(listings_sf)\n\n\nRows: 3,457\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 64, 78, 220, 85, 75, 69, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.13, 0.16, 0.30, 0.15, 0.11, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 51, 51, 5, 7, 51, 51, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 55, 91, 91, 183, 183, 54, 365, 183, 183…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 2, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "7.1 Buffering",
    "text": "7.1 Buffering\nScenario: The authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nSolution: First, we will use st_buffer() of sf package to compute the 5-meter buffers around the cycling paths.\n\n\nShow code\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\n\nFollowed by calculating the area of the buffers using st_area().\n\n\nShow code\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\n\nThen we will derive the total land involved using sum().\n\n\nShow code\nsum(buffer_cycling$AREA)\n\n\n1774367 [m^2]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "7.2 Point-in-polygon count",
    "text": "7.2 Point-in-polygon count\nScenario: A pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nSolution: We will be using two operations in one go, using st_intersects() to identify pre-schools located inside each Planning Subzone, then length() to calculate number of pre-schools identified in each planning subzone.\n\n\nShow code\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nSummary statistics of the new PreSch Count field using summary().\n\n\nShow code\nsummary(mpsz3414$`PreSch Count`)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nListing planning subzone with the most number of pre-school using top_n() of the dplyr package.\n\n\nShow code\ntop_n(mpsz3414, 1, `PreSch Count`)\n\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nNext, to calculate the density of pre-school by planning subzone, we will first use st_area() of sf package to derive the area of each planning subzone.\n\n\nShow code\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\n\nWe will then use mutate() of dplyr package to compute the density.\n\n\nShow code\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#histogram",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#histogram",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "8.1 Histogram",
    "text": "8.1 Histogram\nThe first graph will be a histogram to reveal the distribution of PreSch Density. I will first use hist() of R Graphics, which is limited in its quality and room for customisation.\n\n\nShow code\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\nWe will then make use of ggplot2 functions to create a more comprehensive histogram.\n\n\nShow code\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#scatterplot",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "8.2 Scatterplot",
    "text": "8.2 Scatterplot\nNext, a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\n\nShow code\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "Welcome to IS415 Geospatial Analytics and Applications\nThis is the website for my course work."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home_Ex01",
    "section": "",
    "text": "We will be applying appropriate spatial point patterns analysis methods learned in class to discover the geographical and spatio-temporal distribution of Grab hailing services locations in Singapore."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loading-r-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loading-r-packages",
    "title": "Take-home_Ex01",
    "section": "2.1 Loading R packages",
    "text": "2.1 Loading R packages\nThe R packages that we will be using in this exercise are as follows:\n\narrow: For reading parquet files (Grab-Posisi Dataset)\nlubridate: To handle the date formatting\nsf: Import, manage and process vector-based geospatial data in R.\ntidyverse: a collection of packages for data science tasks\nspatstat: Wide range of useful functions for point pattern analysis and derive kernel density estimation (KDE) layer.\nspNetwork: provides functions to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It also can be used to build spatial matrices (‘listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.\ntmap: Provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\nraster: reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools: Provides a set of tools for manipulating geographic data. In this take-home exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\n# classInt, viridis, rgdal\n\n\n\nShow code\npacman::p_load(arrow, lubridate, sf, tidyverse, spNetwork, tmap, \n               spatstat, raster, maptools)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-the-datasets",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-the-datasets",
    "title": "Take-home_Ex01",
    "section": "2.2 Importing the datasets",
    "text": "2.2 Importing the datasets\nThe datasets that we will be using are as follow:\n\nGrab-Posisi DatasetOpenStreetMap Road DatasetMaster Plan 2019 Subzone Boundary Dataset\n\n\nUsing read_parquet() function from arrow package to import the grab data, then changing pingtimestamp column to datetime object\n\n\nShow code\ngrab_df0 &lt;- read_parquet(\"data/aspatial/part-00000.snappy.parquet\")\ngrab_df1 &lt;- read_parquet(\"data/aspatial/part-00001.snappy.parquet\")\ngrab_df2 &lt;- read_parquet(\"data/aspatial/part-00002.snappy.parquet\")\ngrab_df3 &lt;- read_parquet(\"data/aspatial/part-00003.snappy.parquet\")\ngrab_df4 &lt;- read_parquet(\"data/aspatial/part-00004.snappy.parquet\")\ngrab_df5 &lt;- read_parquet(\"data/aspatial/part-00005.snappy.parquet\")\ngrab_df6 &lt;- read_parquet(\"data/aspatial/part-00006.snappy.parquet\")\ngrab_df7 &lt;- read_parquet(\"data/aspatial/part-00007.snappy.parquet\")\ngrab_df8 &lt;- read_parquet(\"data/aspatial/part-00008.snappy.parquet\")\ngrab_df9 &lt;- read_parquet(\"data/aspatial/part-00009.snappy.parquet\")\n\n\n\n\nShow code\ngrab_df &lt;- bind_rows(grab_df0,\n                     grab_df1,\n                     grab_df2,\n                     grab_df3,\n                     grab_df4,\n                     grab_df5,\n                     grab_df6,\n                     grab_df7,\n                     grab_df8,\n                     grab_df9)\n\ngrab_df$pingtimestamp &lt;- as_datetime(grab_df$pingtimestamp)\n\n\n\n\nTransforming the coordinate system at the same time when we are importing the data\n\n\nShow code\nsg_roads &lt;- st_read(dsn = \"data/geospatial\", layer = \"gis_osm_roads_free_1\") %&gt;% st_transform(crs = 3414)\n\n\nReading layer `gis_osm_roads_free_1' from data source \n  `/Users/jacksontan/Documents/Sashimii0219/IS415-GAA/Take-home_Ex/Take-home_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1759836 features and 10 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 99.66041 ymin: 0.8021131 xmax: 119.2601 ymax: 7.514393\nGeodetic CRS:  WGS 84\n\n\n\n\nTransforming the coordinate system at the same time when we are importing the data\n\n\nShow code\nmpsz2019 &lt;- st_read(\"data/geospatial\", layer = \"MPSZ-2019\") %&gt;% st_transform(crs = 3414)\n\n\nReading layer `MPSZ-2019' from data source \n  `/Users/jacksontan/Documents/Sashimii0219/IS415-GAA/Take-home_Ex/Take-home_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-pre-processing---mpsz2019",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-pre-processing---mpsz2019",
    "title": "Take-home_Ex01",
    "section": "3.1 Data Pre-processing - MPSZ2019",
    "text": "3.1 Data Pre-processing - MPSZ2019\n\n3.1.1 Excluding Outer Islands\nAs grab won’t be able to reach offshore places, we will exclude the outer islands from this dataset. We will do this through the following steps:\n\nFinding the islandsExcluding the islandsChecking out the difference\n\n\nWe will first take a look at the unique planning areas in Singapore using unique() on the PLN_AREA_N column of mpsz2019 dataset.\n\n\nShow code\nunique(mpsz2019$PLN_AREA_N)\n\n\n [1] \"MARINA EAST\"             \"RIVER VALLEY\"           \n [3] \"SINGAPORE RIVER\"         \"WESTERN ISLANDS\"        \n [5] \"MUSEUM\"                  \"MARINE PARADE\"          \n [7] \"SOUTHERN ISLANDS\"        \"BUKIT MERAH\"            \n [9] \"DOWNTOWN CORE\"           \"STRAITS VIEW\"           \n[11] \"QUEENSTOWN\"              \"OUTRAM\"                 \n[13] \"MARINA SOUTH\"            \"ROCHOR\"                 \n[15] \"KALLANG\"                 \"TANGLIN\"                \n[17] \"NEWTON\"                  \"CLEMENTI\"               \n[19] \"BEDOK\"                   \"PIONEER\"                \n[21] \"JURONG EAST\"             \"ORCHARD\"                \n[23] \"GEYLANG\"                 \"BOON LAY\"               \n[25] \"BUKIT TIMAH\"             \"NOVENA\"                 \n[27] \"TOA PAYOH\"               \"TUAS\"                   \n[29] \"JURONG WEST\"             \"SERANGOON\"              \n[31] \"BISHAN\"                  \"TAMPINES\"               \n[33] \"BUKIT BATOK\"             \"HOUGANG\"                \n[35] \"CHANGI BAY\"              \"PAYA LEBAR\"             \n[37] \"ANG MO KIO\"              \"PASIR RIS\"              \n[39] \"BUKIT PANJANG\"           \"TENGAH\"                 \n[41] \"SELETAR\"                 \"SUNGEI KADUT\"           \n[43] \"YISHUN\"                  \"MANDAI\"                 \n[45] \"PUNGGOL\"                 \"CHOA CHU KANG\"          \n[47] \"SENGKANG\"                \"CHANGI\"                 \n[49] \"CENTRAL WATER CATCHMENT\" \"SEMBAWANG\"              \n[51] \"WESTERN WATER CATCHMENT\" \"WOODLANDS\"              \n[53] \"NORTH-EASTERN ISLANDS\"   \"SIMPANG\"                \n[55] \"LIM CHU KANG\"           \n\n\nShow code\nplot(mpsz2019)\n\n\n\n\n\nNote that there are 3 areas with island in their name, mainly “NORTH-EASTERN ISLANDS”, “SOUTHERN ISLANDS”, and “WESTERN ISLANDS”.\n\n\nTo exclude the islands, we simply have to pass a condition to exclude these islands in the subset function.\n\n\nShow code\nmpsz2019_new &lt;- subset(mpsz2019, !(PLN_AREA_N %in% \n            c(\"NORTH-EASTERN ISLANDS\", \"SOUTHERN ISLANDS\", \"WESTERN ISLANDS\")))\n\n\n\n\nGreat! Now let’s check if we indeed removed the maps!\n\n\nShow code\ntmap_mode('plot')\nbefore &lt;- tm_shape(mpsz2019) +\n  tm_polygons(\"PLN_AREA_N\") +\n  tmap_options(max.categories = 53)\nafter &lt;- tm_shape(mpsz2019_new) +\n  tm_polygons(\"PLN_AREA_N\") +\n  tmap_options(max.categories = 53)\n\ntmap_arrange(before, after)\n\n\n\n\n\n\n\n\n\n\n3.1.2 Invalid Geometries\nWe will be using the st_is_valid() function to test for invalid geometries.\n\n\nShow code\ntest &lt;- st_is_valid(mpsz2019_new,reason=TRUE)\n\n# Number of invalid geometries\nlength(which(test!= \"Valid Geometry\"))\n\n\n[1] 3\n\n\nShow code\n# Reason\ntest[which(test!= \"Valid Geometry\")]\n\n\n[1] \"Ring Self-intersection[26922.5243000389 27027.610899987]\" \n[2] \"Ring Self-intersection[38991.2589000446 31986.5599999869]\"\n[3] \"Ring Self-intersection[14484.6860000313 31330.1319999856]\"\n\n\nWe can see that there are 3 invalid geometries. Let’s fix them using st_make_valid().\n\n\nShow code\nmpsz2019_new&lt;- st_make_valid(mpsz2019_new)\nlength(which(st_is_valid(mpsz2019_new) == FALSE))\n\n\n[1] 0\n\n\n\n\n3.1.3 Missing Values\n\n\nShow code\nmpsz2019_new[rowSums(is.na(mpsz2019_new))!=0,]\n\n\nSimple feature collection with 0 features and 6 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] SUBZONE_N  SUBZONE_C  PLN_AREA_N PLN_AREA_C REGION_N   REGION_C   geometry  \n&lt;0 rows&gt; (or 0-length row.names)\n\n\nUsing the code above, we can see that there are no missing values.\n\n\n3.1.4 Creating boundary?\n\n\nShow code\nsg_boundary &lt;- mpsz2019_new %&gt;% st_union()\nplot(sg_boundary)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-pre-processing---openstreetmap-road-dataset",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-pre-processing---openstreetmap-road-dataset",
    "title": "Take-home_Ex01",
    "section": "3.2 Data Pre-processing - OpenStreetMap Road Dataset",
    "text": "3.2 Data Pre-processing - OpenStreetMap Road Dataset\n\n3.2.1 Limiting the dataset\nAs the dataset contains data from Malaysia and Brunei as well, we will use st_intersection() to limit the data to only Singapore.\n\n\nShow code\npoints_within_sg &lt;- st_intersection(sg_roads, mpsz2019_new)\n\n\nNow, we can see that in points_within_sg it only contain Singapore road data, combined with the other values from mpsz2019 like “PLN_AREA_N” used above.\n\n\nShow code\ncolnames(points_within_sg)\n\n\n [1] \"osm_id\"     \"code\"       \"fclass\"     \"name\"       \"ref\"       \n [6] \"oneway\"     \"maxspeed\"   \"layer\"      \"bridge\"     \"tunnel\"    \n[11] \"SUBZONE_N\"  \"SUBZONE_C\"  \"PLN_AREA_N\" \"PLN_AREA_C\" \"REGION_N\"  \n[16] \"REGION_C\"   \"geometry\"  \n\n\nShow code\nhead(points_within_sg)\n\n\nSimple feature collection with 6 features and 16 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 31466.72 ymin: 30680.54 xmax: 32815.21 ymax: 30873.74\nProjected CRS: SVY21 / Singapore TM\n        osm_id code        fclass               name  ref oneway maxspeed layer\n4052  23946437 5122   residential          Rhu Cross &lt;NA&gt;      F       50     0\n9668  32605139 5131 motorway_link               &lt;NA&gt; &lt;NA&gt;      F       40     0\n20076 46337834 5131 motorway_link               &lt;NA&gt; &lt;NA&gt;      F       50    -2\n21690 49961799 5111      motorway East Coast Parkway  ECP      F       70     1\n26543 74722808 5111      motorway East Coast Parkway  ECP      F       70     1\n29808 99007260 5131 motorway_link               &lt;NA&gt; &lt;NA&gt;      F       50     1\n      bridge tunnel   SUBZONE_N SUBZONE_C  PLN_AREA_N PLN_AREA_C       REGION_N\n4052       F      F MARINA EAST    MESZ01 MARINA EAST         ME CENTRAL REGION\n9668       F      F MARINA EAST    MESZ01 MARINA EAST         ME CENTRAL REGION\n20076      F      T MARINA EAST    MESZ01 MARINA EAST         ME CENTRAL REGION\n21690      F      F MARINA EAST    MESZ01 MARINA EAST         ME CENTRAL REGION\n26543      T      F MARINA EAST    MESZ01 MARINA EAST         ME CENTRAL REGION\n29808      T      F MARINA EAST    MESZ01 MARINA EAST         ME CENTRAL REGION\n      REGION_C                       geometry\n4052        CR LINESTRING (31889.45 30760....\n9668        CR LINESTRING (32768.57 30857....\n20076       CR LINESTRING (32815.21 30873....\n21690       CR LINESTRING (32365.45 30845....\n26543       CR LINESTRING (31611.63 30720....\n29808       CR LINESTRING (31611.63 30720....\n\n\n\n\n3.2.2 Invalid Geometries\nAgain, using the st_is_valid() function to test for invalid geometries.\n\n\nShow code\ntest &lt;- st_is_valid(points_within_sg,reason=TRUE)\n\n# Number of invalid geometries\nlength(which(test!= \"Valid Geometry\"))\n\n\n[1] 0\n\n\nShow code\n# Reason\ntest[which(test!= \"Valid Geometry\")]\n\n\ncharacter(0)\n\n\nNo invalid geometries!\n\n\n3.2.3 Missing Values / Dropping Columns\n\n\nShow code\npoints_within_sg[rowSums(is.na(points_within_sg))!=0,]\n\n\nSimple feature collection with 232766 features and 16 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 2679.373 ymin: 23099.51 xmax: 50957.8 ymax: 50220.06\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n         osm_id code        fclass           name  ref oneway maxspeed layer\n4052   23946437 5122   residential      Rhu Cross &lt;NA&gt;      F       50     0\n9668   32605139 5131 motorway_link           &lt;NA&gt; &lt;NA&gt;      F       40     0\n20076  46337834 5131 motorway_link           &lt;NA&gt; &lt;NA&gt;      F       50    -2\n29808  99007260 5131 motorway_link           &lt;NA&gt; &lt;NA&gt;      F       50     1\n45723 140562813 5131 motorway_link           &lt;NA&gt; &lt;NA&gt;      F       70    -1\n45728 140562819 5131 motorway_link           &lt;NA&gt; &lt;NA&gt;      F       50     0\n45731 140562823 5131 motorway_link           &lt;NA&gt; &lt;NA&gt;      F       60    -2\n45733 140562826 5131 motorway_link           &lt;NA&gt; &lt;NA&gt;      F       40     0\n52966 150819034 5141       service Bay East Drive &lt;NA&gt;      B        0     0\n84664 174717984 5153       footway           &lt;NA&gt; &lt;NA&gt;      B        0     0\n      bridge tunnel   SUBZONE_N SUBZONE_C  PLN_AREA_N PLN_AREA_C       REGION_N\n4052       F      F MARINA EAST    MESZ01 MARINA EAST         ME CENTRAL REGION\n9668       F      F MARINA EAST    MESZ01 MARINA EAST         ME CENTRAL REGION\n20076      F      T MARINA EAST    MESZ01 MARINA EAST         ME CENTRAL REGION\n29808      T      F MARINA EAST    MESZ01 MARINA EAST         ME CENTRAL REGION\n45723      F      F MARINA EAST    MESZ01 MARINA EAST         ME CENTRAL REGION\n45728      F      F MARINA EAST    MESZ01 MARINA EAST         ME CENTRAL REGION\n45731      F      T MARINA EAST    MESZ01 MARINA EAST         ME CENTRAL REGION\n45733      F      F MARINA EAST    MESZ01 MARINA EAST         ME CENTRAL REGION\n52966      F      F MARINA EAST    MESZ01 MARINA EAST         ME CENTRAL REGION\n84664      F      F MARINA EAST    MESZ01 MARINA EAST         ME CENTRAL REGION\n      REGION_C                       geometry\n4052        CR LINESTRING (31889.45 30760....\n9668        CR LINESTRING (32768.57 30857....\n20076       CR LINESTRING (32815.21 30873....\n29808       CR LINESTRING (31611.63 30720....\n45723       CR LINESTRING (32782.42 30754....\n45728       CR LINESTRING (32645.37 30683....\n45731       CR LINESTRING (32809.68 30108....\n45733       CR LINESTRING (32609.11 30700....\n52966       CR LINESTRING (32173.46 30036....\n84664       CR LINESTRING (31750.06 30644....\n\n\nBy using the code above, we can see that majority of the missing values are in the ‘name’ and ‘ref’ column. Therefore, let’s drop the irrelevant columns first before we try it again!\n\n\nShow code\nsg_roads_new &lt;- points_within_sg[c(\"osm_id\", \"code\", \"fclass\", \"PLN_AREA_N\", \"geometry\")]\n\n\nWe only kept “osm_id”, “code”, “fclass”, and “PLN_AREA_N” columns.\n\n\nShow code\nsg_roads_new[rowSums(is.na(sg_roads_new))!=0,]\n\n\nSimple feature collection with 0 features and 4 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n[1] osm_id     code       fclass     PLN_AREA_N geometry  \n&lt;0 rows&gt; (or 0-length row.names)\n\n\nNo more missing values here.\nOur map so far:\n\n\nShow code\ntm_shape(sg_boundary) +\n  tm_polygons() +\n  tm_shape(sg_roads_new) +\n  tm_lines(\"PLN_AREA_N\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-pre-processing---grab-posisi-dataset",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-pre-processing---grab-posisi-dataset",
    "title": "Take-home_Ex01",
    "section": "3.3 Data Pre-processing - Grab-Posisi Dataset",
    "text": "3.3 Data Pre-processing - Grab-Posisi Dataset\nThe Grab-Posisi Dataset is an Aspatial dataset, different from the two we prepared above. As such, the pre-processing is slightly different too.\n\n3.3.1 Getting the Origin and Destination Locations\nThe code below is a chain of dplyr pipes to group the trips by their id and extract the first pingtimestamp row of each trip in order to get the origin of it.\n\n\nShow code\norigin_df &lt;- grab_df %&gt;%\n  group_by(trj_id) %&gt;%\n  arrange(pingtimestamp) %&gt;% \n  filter(row_number()==1) %&gt;% \n  mutate(weekday = wday(pingtimestamp,\n                        label=TRUE,\n                        abbr=TRUE),\n         start_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n\n\nShow code\ndestination_df &lt;- grab_df %&gt;%\n  group_by(trj_id) %&gt;%\n  arrange(desc(pingtimestamp)) %&gt;% \n  # Same as previous code but desc, so ending location\n  filter(row_number()==1) %&gt;%\n  mutate(weekday = wday(pingtimestamp,\n                        label=TRUE,\n                        abbr=TRUE),\n         end_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n\n\n3.3.2 Converting to SF format from Dataframe\nWe will need the files in SF format first before we can use it for further geospatial analysis.\n\n\nShow code\norigin_sf &lt;- st_as_sf(origin_df, \n                       coords = c(\"rawlng\", \"rawlat\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\ndest_sf &lt;- st_as_sf(destination_df, \n                       coords = c(\"rawlng\", \"rawlat\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\n\n\n\n3.3.3 Invalid Geometries\n\n\nShow code\ntest &lt;- st_is_valid(origin_sf,reason=TRUE)\nlength(which(test!= \"Valid Geometry\"))\n\n\n[1] 0\n\n\nShow code\ntest &lt;- st_is_valid(dest_sf,reason=TRUE)\nlength(which(test!= \"Valid Geometry\"))\n\n\n[1] 0\n\n\n\n\n3.3.4 Missing Files\n\n\nShow code\norigin_sf[rowSums(is.na(origin_sf))!=0,]\n\n\nSimple feature collection with 0 features and 10 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 0 × 11\n# Groups:   trj_id [0]\n# ℹ 11 variables: trj_id &lt;chr&gt;, driving_mode &lt;chr&gt;, osname &lt;chr&gt;,\n#   pingtimestamp &lt;dttm&gt;, speed &lt;dbl&gt;, bearing &lt;int&gt;, accuracy &lt;dbl&gt;,\n#   weekday &lt;ord&gt;, start_hr &lt;fct&gt;, day &lt;fct&gt;, geometry &lt;GEOMETRY [m]&gt;\n\n\nShow code\ndest_sf[rowSums(is.na(dest_sf))!=0,]\n\n\nSimple feature collection with 0 features and 10 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 0 × 11\n# Groups:   trj_id [0]\n# ℹ 11 variables: trj_id &lt;chr&gt;, driving_mode &lt;chr&gt;, osname &lt;chr&gt;,\n#   pingtimestamp &lt;dttm&gt;, speed &lt;dbl&gt;, bearing &lt;int&gt;, accuracy &lt;dbl&gt;,\n#   weekday &lt;ord&gt;, end_hr &lt;fct&gt;, day &lt;fct&gt;, geometry &lt;GEOMETRY [m]&gt;\n\n\nNo missing values, we are almost ready.\n\n\n3.3.5 Removing points on the islands\n\n\nShow code\norigin_sf_new &lt;- st_intersection(origin_sf, mpsz2019_new)\ndest_sf_new &lt;- st_intersection(dest_sf, mpsz2019_new)\n\n\nTo verify that the points that we removed is indeed from the islands, here’s a chunk of code to prove:\n\n\nShow code\n# Finding out points removed\ndiff_id &lt;- origin_sf$trj_id[!(origin_sf$trj_id %in% origin_sf_new$trj_id)]\n\n# Extracting full information of these points\noutliers &lt;- origin_sf[(origin_sf$trj_id %in% diff_id), ]\n\n# Checking where these places are from\nunique(st_intersection(outliers, mpsz2019)$PLN_AREA_N)\n\n\n[1] \"WESTERN ISLANDS\"  \"SOUTHERN ISLANDS\"\n\n\nThey are indeed from “WESTERN ISLANDS” and “SOUTHERN ISLANDS”.\n\n\n3.3.6 Dropping Unnecessary Columns\nNow that our grab dataset is almost ready, we need to decide which column we should drop. Here are the columns in both origin_sf_new and dest_sf_new:\n\n\nShow code\ncolnames(origin_sf_new)\n\n\n [1] \"trj_id\"        \"driving_mode\"  \"osname\"        \"pingtimestamp\"\n [5] \"speed\"         \"bearing\"       \"accuracy\"      \"weekday\"      \n [9] \"start_hr\"      \"day\"           \"SUBZONE_N\"     \"SUBZONE_C\"    \n[13] \"PLN_AREA_N\"    \"PLN_AREA_C\"    \"REGION_N\"      \"REGION_C\"     \n[17] \"geometry\"     \n\n\nShow code\ncolnames(dest_sf_new)\n\n\n [1] \"trj_id\"        \"driving_mode\"  \"osname\"        \"pingtimestamp\"\n [5] \"speed\"         \"bearing\"       \"accuracy\"      \"weekday\"      \n [9] \"end_hr\"        \"day\"           \"SUBZONE_N\"     \"SUBZONE_C\"    \n[13] \"PLN_AREA_N\"    \"PLN_AREA_C\"    \"REGION_N\"      \"REGION_C\"     \n[17] \"geometry\"     \n\n\nWe will definitely be dropping the columns merged from mpsz2019_new (other than PLN_AREA_N), but what about “driving_mode”, “osname”, “speed”, “bearing”, and “accuracy”? Let’s first take a look at them.\n\ndriving_modeosnamespeedbearingaccuracy\n\n\n\n\nShow code\nunique(origin_sf_new$driving_mode)\n\n\n[1] \"car\"\n\n\nSeeing that there is only 1 constant in the column, it is safe for us to drop this column.\n\n\n\n\nShow code\nunique(origin_sf_new$osname)\n\n\n[1] \"ios\"     \"android\"\n\n\nThere are 2 values, mainly “ios” and “android”. Arguments can be made that we can analyse the behavior of both type in terms of using grab hailing services, but that’s not what we will doing so we will drop this as well.\n\n\nAs we are analysing start/stop points, speed will not be a relevant factor hence we will be dropping them.\n\n\nNot relevant as well, hence dropping.\n\n\nAccording to research paper published on Grab website, this is the definition of the accuracy column:\n“…the accuracy level roughly indicates the radius of the circle within which the true location lies with a certain probability. The lower the accuracy level, the more precise the reported GPS ping is.”\nWith that, let’s take a look at the distribution of accuracy score.\n\n\nShow code\nplot(origin_sf_new$accuracy)\n\n\n\n\n\n\n\nShow code\nggplot(origin_sf_new, \n       aes(x=rownames(origin_sf_new), y=accuracy)) + \n  geom_point(size = 2)\n\n\n\n\n\nShow code\nggplot(dest_sf_new, \n       aes(x=rownames(dest_sf_new), y=accuracy)) + \n  geom_point(size = 2)\n\n\n\n\n\nFrom the plot, we can see that there are 3 clear outliers with accuracy above 180~ for origin_sf_new, and 1 for dest_sf_new. Now let’s extract these trips.\n\n\nShow code\norigin_sf_new[origin_sf_new$accuracy &gt; 180, ]\n\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 29008.44 ymin: 32353.78 xmax: 29008.44 ymax: 32353.78\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 1 × 17\n  trj_id driving_mode osname pingtimestamp       speed bearing accuracy weekday\n  &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;  &lt;dttm&gt;              &lt;dbl&gt;   &lt;int&gt;    &lt;dbl&gt; &lt;ord&gt;  \n1 59560  car          ios    2019-04-16 00:28:59    -1      26      728 Tue    \n# ℹ 9 more variables: start_hr &lt;fct&gt;, day &lt;fct&gt;, SUBZONE_N &lt;chr&gt;,\n#   SUBZONE_C &lt;chr&gt;, PLN_AREA_N &lt;chr&gt;, PLN_AREA_C &lt;chr&gt;, REGION_N &lt;chr&gt;,\n#   REGION_C &lt;chr&gt;, geometry &lt;POINT [m]&gt;\n\n\nShow code\ndest_sf_new[dest_sf_new$accuracy &gt; 500, ]\n\n\nSimple feature collection with 7 features and 16 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 28983.51 ymin: 29952.1 xmax: 33721.09 ymax: 34502.5\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 7 × 17\n  trj_id driving_mode osname pingtimestamp       speed bearing accuracy weekday\n  &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;  &lt;dttm&gt;              &lt;dbl&gt;   &lt;int&gt;    &lt;dbl&gt; &lt;ord&gt;  \n1 54788  car          ios    2019-04-09 11:06:56    -1     203     1414 Tue    \n2 14443  car          ios    2019-04-11 01:09:18    -1     223     1414 Thu    \n3 36434  car          ios    2019-04-18 07:41:35    -1     126      806 Thu    \n4 60701  car          ios    2019-04-13 03:16:02    -1     130      818 Sat    \n5 24103  car          ios    2019-04-11 13:19:30    -1     117     1402 Thu    \n6 58922  car          ios    2019-04-13 15:50:44    -1      31     1414 Sat    \n7 68340  car          ios    2019-04-12 11:55:48    -1      10     1414 Fri    \n# ℹ 9 more variables: end_hr &lt;fct&gt;, day &lt;fct&gt;, SUBZONE_N &lt;chr&gt;,\n#   SUBZONE_C &lt;chr&gt;, PLN_AREA_N &lt;chr&gt;, PLN_AREA_C &lt;chr&gt;, REGION_N &lt;chr&gt;,\n#   REGION_C &lt;chr&gt;, geometry &lt;POINT [m]&gt;\n\n\nTo ensure that our data is of utmost accuracy, we will drop these trips, before we drop the accuracy column as well (as we will not need it anymore).\n\n\nShow code\norigin_sf_new &lt;- subset(origin_sf_new, accuracy &lt; 180)\ndest_sf_new &lt;- subset(dest_sf_new, accuracy &lt; 500)\n\n\n\n\n\nWith that done, we can now drop the columns that we don’t need.\n\n\nShow code\norigin_sf_new &lt;- origin_sf_new[, c(1, 4,  8:10, 13, 17)]\ndest_sf_new &lt;- dest_sf_new[, c(1, 4,  8:10, 13, 17)]\n\n\n\n\n3.3.7 Duplicated Points\nLastly, let’s check for duplicated points on the map.\n\n\nShow code\n# Check for any duplicates\nany(duplicated(origin_sf_new))\n\n\n[1] FALSE\n\n\nShow code\n# Count the number of duplicates\nsum(multiplicity(origin_sf_new) &gt; 1)\n\n\n[1] 0\n\n\nNo duplicated points!"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#verifying-coordinate-system",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#verifying-coordinate-system",
    "title": "Take-home_Ex01",
    "section": "3.4 Verifying Coordinate System",
    "text": "3.4 Verifying Coordinate System\nIt is important for the data to be in the right coordinate reference system (CRS). In this assignment, all spatial data will be projected in EPSG:3414, which is a projected coordinate system for Singapore.\n\nmpsz2019_newsg_roads_neworigin_sf and dest_sf\n\n\n\n\nShow code\nst_crs(mpsz2019_new)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\n\nShow code\nst_crs(sg_roads_new)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\n\nShow code\nst_crs(origin_sf_new)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nShow code\nst_crs(dest_sf_new)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nThey are all in the correct CRS!"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#plotting-spatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#plotting-spatial-data",
    "title": "Take-home_Ex01",
    "section": "3.5 Plotting Spatial Data",
    "text": "3.5 Plotting Spatial Data\nFinally, plotting all three datasets together to ensure that they have a consistent projection system.\n\n\nShow code\ntm_shape(sg_boundary) +\n  tm_polygons() +\ntm_shape(sg_roads_new) + \n  tm_lines(\"PLN_AREA_N\") + \ntm_shape(origin_sf_new) +\n  tm_dots()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-analysis",
    "title": "Take-home_Ex01",
    "section": "3.6 Exploratory Data Analysis",
    "text": "3.6 Exploratory Data Analysis\nBefore we begin our Geospatial Analysis, let’s first take a closer look at the Grab dataset.\n\n3.6.1 Day of the Week\nThe distribution of the trips across all 7 days of the week looks even.\n\n\nShow code\nggplot(origin_sf_new, aes(x=weekday)) + geom_bar()\n\n\n\n\n\nShow code\nggplot(dest_sf_new, aes(x=weekday)) + geom_bar()\n\n\n\n\n\n\n\n3.6.2 Planning Area\nFirst let us look at the top 10 planning areas for grab ride origin points. Tampines is the Planning Area with the most origin points.\n\n\nShow code\norigin_pl_area &lt;- origin_sf_new %&gt;%\n  group_by(PLN_AREA_N) %&gt;%\n  summarise(total_count=n()) %&gt;%\n  top_n(10, total_count) %&gt;%\n  .$PLN_AREA_N\n\nggplot(origin_sf_new[origin_sf_new$PLN_AREA_N %in% origin_pl_area,], \n       aes(x=PLN_AREA_N)) + geom_bar() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n  labs(title = \"Trips Origin Distribution by Planning Area\",\n       x = \"Planning Area\",\n       y = \"Number of Trips\")\n\n\n\n\n\nThen for the destination points.\n\n\nShow code\ndest_pl_area &lt;- dest_sf_new %&gt;%\n  group_by(PLN_AREA_N) %&gt;%\n  summarise(total_count=n()) %&gt;%\n  top_n(10, total_count) %&gt;%\n  .$PLN_AREA_N\n\nggplot(dest_sf_new[dest_sf_new$PLN_AREA_N %in% dest_pl_area,], \n       aes(x=PLN_AREA_N)) + geom_bar() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n  labs(title = \"Trips Destination Distribution by Planning Area\",\n       x = \"Planning Area\",\n       y = \"Number of Trips\")\n\n\n\n\n\n6 out of 10 of the Planning Areas remains the same for destination points, mainly TAMPINES, WOODLANDS, YISHUN, QUEENSTOWN, BUKIT MERAH, and CHANGI. This time however, the Planning Area with the most destination points is Changi.\n\n\n3.6.3 Starting Hour\n\n\nShow code\norigin_sf_new$start_hr &lt;- factor(origin_sf_new$start_hr, levels = 0:23)\n\nggplot(origin_sf_new, aes(x = start_hr)) +\n  geom_bar() +\n  labs(title = \"Trips Distribution by Start Hour\",\n       x = \"Start Hour\",\n       y = \"Number of Trips\")\n\n\n\n\n\nFrom the graph, we can see that the starting hour peaks at midnight (12am - 1am) and morning (9am - 10am), the former probably due to the lack of public transport after operating hours, and the latter from rush hour."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-data-format",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-data-format",
    "title": "Take-home_Ex01",
    "section": "4.1 Converting data format",
    "text": "4.1 Converting data format\n\n4.1.1 Creating point ppp objects\nIn the code chunk below, as.ppp() function is used to derive a ppp object layer directly from a sf tibble data.frame.\n\n\nShow code\norigin_ppp &lt;- as.ppp(origin_sf_new)\nsummary(origin_ppp)\n\n\nMarked planar point pattern:  27871 points\nAverage intensity 2.631202e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n    27871 character character \n\nWindow: rectangle = [3628.24, 49845.23] x [26770.58, 49689.64] units\n                    (46220 x 22920 units)\nWindow area = 1059250000 square units\n\n\nShow code\ndest_ppp &lt;- as.ppp(dest_sf_new)\nsummary(dest_ppp)\n\n\nMarked planar point pattern:  27811 points\nAverage intensity 2.645533e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n    27811 character character \n\nWindow: rectangle = [3637.21, 49870.63] x [26770.04, 49507.79] units\n                    (46230 x 22740 units)\nWindow area = 1051240000 square units\n\n\n\n\n4.1.2 Creating owin objects\nIn the code chunk as.owin() is used to create an owin object class from polygon sf tibble data.frame. In this case, we will be converting the sg_boundary polygon.\n\n\nShow code\nsg_boundary_owin &lt;- as.owin(sg_boundary)\n\n\n\n\n4.1.3 Combining point events object and owin object\nWe will now combine singapore’s boundary and the origin and destination points into one.\n\n\nShow code\noriginSG_ppp = origin_ppp[sg_boundary_owin]\ndestSG_ppp = dest_ppp[sg_boundary_owin]\n\n\n\n\nShow code\nplot(destSG_ppp)\n\n\n\n\n\n\n\nShow code\nsummary(destSG_ppp)\n\n\nMarked planar point pattern:  27811 points\nAverage intensity 4.184642e-05 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n    27811 character character \n\nWindow: polygonal boundary\n37 separate polygons (29 holes)\n                  vertices         area relative.area\npolygon 1            12666  6.63014e+08      9.98e-01\npolygon 2              285  1.61128e+06      2.42e-03\npolygon 3               27  1.50315e+04      2.26e-05\npolygon 4 (hole)        41 -4.01660e+04     -6.04e-05\npolygon 5 (hole)       317 -5.11280e+04     -7.69e-05\npolygon 6 (hole)         3 -4.14099e-04     -6.23e-13\npolygon 7               30  2.80002e+04      4.21e-05\npolygon 8 (hole)         4 -2.86396e-01     -4.31e-10\npolygon 9 (hole)         3 -1.81439e-04     -2.73e-13\npolygon 10 (hole)        3 -8.68789e-04     -1.31e-12\npolygon 11 (hole)        3 -5.99535e-04     -9.02e-13\npolygon 12 (hole)        3 -3.04561e-04     -4.58e-13\npolygon 13 (hole)        3 -4.46076e-04     -6.71e-13\npolygon 14 (hole)        3 -3.39794e-04     -5.11e-13\npolygon 15 (hole)        3 -4.52043e-05     -6.80e-14\npolygon 16 (hole)        3 -3.90173e-05     -5.87e-14\npolygon 17 (hole)        3 -9.59850e-05     -1.44e-13\npolygon 18 (hole)        4 -2.54488e-04     -3.83e-13\npolygon 19 (hole)        4 -4.28453e-01     -6.45e-10\npolygon 20 (hole)        4 -2.18616e-04     -3.29e-13\npolygon 21 (hole)        5 -2.44411e-04     -3.68e-13\npolygon 22 (hole)        5 -3.64686e-02     -5.49e-11\npolygon 23              71  8.18750e+03      1.23e-05\npolygon 24 (hole)        6 -8.37554e-01     -1.26e-09\npolygon 25 (hole)       38 -7.79904e+03     -1.17e-05\npolygon 26 (hole)        3 -3.41897e-05     -5.14e-14\npolygon 27 (hole)        3 -3.65499e-03     -5.50e-12\npolygon 28 (hole)        3 -4.95057e-02     -7.45e-11\npolygon 29              91  1.49663e+04      2.25e-05\npolygon 30 (hole)        5 -2.92235e-04     -4.40e-13\npolygon 31 (hole)        3 -7.43616e-06     -1.12e-14\npolygon 32 (hole)      270 -1.21455e+03     -1.83e-06\npolygon 33 (hole)       19 -4.39650e+00     -6.62e-09\npolygon 34 (hole)       35 -1.38385e+02     -2.08e-07\npolygon 35 (hole)       23 -1.99656e+01     -3.00e-08\npolygon 36              71  5.63061e+03      8.47e-06\npolygon 37              10  1.99717e+02      3.01e-07\nenclosing rectangle: [2667.54, 55941.94] x [21448.47, 50256.33] units\n                     (53270 x 28810 units)\nWindow area = 664597000 square units\nFraction of frame area: 0.433\n\n\n\n\n4.1.4 Rescale\nThe density values of the output range from 0 to 0.000035 which is way too small to comprehend, and it is computed in “number of points per square meter”. Therefore, we are going to use rescale() to covert the unit of measurement from meter to kilometer.\n\n\nShow code\noriginSG_ppp.km &lt;- rescale(originSG_ppp, 1000, \"km\")\ndestSG_ppp.km &lt;- rescale(destSG_ppp, 1000, \"km\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#deriving-traditional-kernel-density-estimation-kde-layers",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#deriving-traditional-kernel-density-estimation-kde-layers",
    "title": "Take-home_Ex01",
    "section": "4.2 Deriving Traditional Kernel Density Estimation (KDE) Layers",
    "text": "4.2 Deriving Traditional Kernel Density Estimation (KDE) Layers\n\n4.2.1 Automatic bandwidth selection method\nWe will first compute the kernel density by using density() of the spatstat package, with the default method bw.diggle().\n\n\nShow code\nkde_originSG_bw &lt;- density(originSG_ppp.km,\n                              sigma=bw.ppl,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nplot(kde_originSG_bw, main = \"Kernel Density Estimation Layer\")\n\n\n\n\n\nLooking at all the different methods, we can see that bw.diggle() is still the best among the automatic bandwidth selection method.\n\n\nShow code\nbw.CvL(originSG_ppp.km)\n\n\n   sigma \n3.147573 \n\n\n\n\nShow code\nbw.scott(originSG_ppp.km)\n\n\n  sigma.x   sigma.y \n1.5973830 0.9321636 \n\n\n\n\nShow code\nbw.ppl(originSG_ppp.km)\n\n\n    sigma \n0.1238747 \n\n\n\n\nShow code\nbw.diggle(originSG_ppp.km)\n\n\n      sigma \n0.008087202 \n\n\n\n\nShow code\nkde_originSG_ppl &lt;- density(originSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_originSG_bw, main = \"bw.diggle\")\nplot(kde_originSG_ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n4.2.2 Computing KDE by using fixed bandwidth\nHaving tried automatic bandwidth selection method, let’s try computing KDE by using a fixed bandwidth defined by us. In our case, we will define a fixed bandwidth of 800m (or 0.8km).\n\n\nShow code\nkde_originSG_500 &lt;- density(originSG_ppp.km, sigma=0.5, edge=TRUE, kernel=\"gaussian\")\nplot(kde_originSG_500)\n\n\n\n\n\n\n\n4.2.3 Computing KDE by using adaptive bandwidth\nFixed bandwidth method, however, is very sensitive to highly skewed distribution of spatial point patterns over geographical units, for example urban versus rural. To overcome this, we can try using adaptive bandwidth instead.\n\n\nShow code\nkde_childcareSG_adaptive &lt;- adaptive.density(originSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n4.2.4 Method we are using\nAs the KDE layer using fixed bandwidth with gaussian kernel plots a graph that allows for meaningful analysis at a glance, we will be using that for the steps moving forward.\n\n\nShow code\nkde_originSG_500 &lt;- density(originSG_ppp.km, sigma=0.5, edge=TRUE, kernel=\"gaussian\")\nplot(kde_originSG_500)\n\n\n\n\n\nShow code\nkde_destSG_500 &lt;- density(destSG_ppp.km, sigma=0.5, edge=TRUE, kernel=\"gaussian\")\nplot(kde_destSG_500)\n\n\n\n\n\nShow code\npar(mfrow=c(1,2))\nplot(kde_originSG_500, main = \"Origin KDE Layer\")\nplot(kde_destSG_500, main = \"Destination KDE layer\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#combining-kde-layers",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#combining-kde-layers",
    "title": "Take-home_Ex01",
    "section": "4.3 Combining KDE layers",
    "text": "4.3 Combining KDE layers\n\n4.3.1 Converting KDE layers into grid object\nIn order for us to map the KDE layer of these points to our map, we first need to convert it into grid object.\n\n\nShow code\ngridded_kde_originSG_500 &lt;- as.SpatialGridDataFrame.im(kde_originSG_500)\nspplot(gridded_kde_originSG_500)\n\n\n\n\n\nShow code\ngridded_kde_destSG_500 &lt;- as.SpatialGridDataFrame.im(kde_destSG_500)\nspplot(gridded_kde_destSG_500)\n\n\n\n\n\n\n\n4.3.2 Converting KDE layers into grid object\nWe will then convert the gridded kernel density objects into RasterLayer object by using raster() of raster package. As the RasterLayer object does not include CRS information, we will need to manually assign it to them as well.\n\n\nShow code\nkde_originSG_500_raster &lt;- raster(gridded_kde_originSG_500)\nprojection(kde_originSG_500_raster) &lt;- CRS(\"+init=EPSG:3414 +datum=WGS84 +units=km\")\nkde_originSG_500_raster\n\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4162063, 0.2250614  (x, y)\nextent     : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=km +no_defs \nsource     : memory\nnames      : v \nvalues     : -1.552973e-14, 591.2389  (min, max)\n\n\nShow code\nkde_destSG_500_raster &lt;- raster(gridded_kde_destSG_500)\nprojection(kde_destSG_500_raster) &lt;- CRS(\"+init=EPSG:3414 +datum=WGS84 +units=km\")\nkde_destSG_500_raster\n\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4162063, 0.2250614  (x, y)\nextent     : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=km +no_defs \nsource     : memory\nnames      : v \nvalues     : -1.361913e-14, 526.6182  (min, max)\n\n\n\n\n4.3.3 Overlaying KDE layer on tmap plot\nTo further explore the map, we will now be overlaying the KDE layer both onto OpenStreetMap of Singapore, and also on the Singapore Planning Area layer and OSM road layer that we have pre-processed.\n\n4.3.3.1 Overlay on OpenStreetMap\n\nOriginDestination\n\n\n\n\nShow code\ntmap_mode(\"view\")\ntm_basemap(leaflet::providers$OpenStreetMap) +\ntm_shape(kde_originSG_500_raster) + \n  tm_raster(\"v\", alpha = 0.7,\n          palette = \"YlOrRd\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\nShow code\ntmap_mode(\"plot\")\n\n\n\n\n\n\nShow code\ntmap_mode(\"view\")\ntm_basemap(leaflet::providers$OpenStreetMap) +\ntm_shape(kde_destSG_500_raster) + \n  tm_raster(\"v\", alpha = 0.7,\n          palette = \"YlOrRd\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\nShow code\ntmap_mode(\"plot\")\n\n\n\n\n\nAs you can see from the plot, there are certain planning areas that are hotspots for hailing of Grab ride service, in particular Central Region (Orchard, Newton etc), Woodlands, Punggol, Tampines, and most notably Changi (where the airport lies).\n\n\n4.3.3.2 Overlay on Planning Area and OSM Road Layers\nTo further confirm our observation, let’s plot the KDE layer over our Planning Area and OSM Road Layers.\n\nOriginDestination\n\n\n\n\nShow code\ntmap_mode(\"view\")\ntm_shape(mpsz2019_new) +\n  tm_polygons(\"PLN_AREA_N\") +\ntm_shape(kde_originSG_500_raster) + \n  tm_raster(\"v\", alpha = 0.7,\n          palette = \"YlOrRd\")\n\n\n\n\n\n\n\n\n\n\n\nShow code\ntmap_mode(\"view\")\ntm_shape(mpsz2019_new) +\n  tm_polygons(\"PLN_AREA_N\") +\ntm_shape(kde_destSG_500_raster) + \n  tm_raster(\"v\", alpha = 0.7,\n          palette = \"YlOrRd\")\n\n\n\n\n\n\n\n\n\n\nThe common overlapping Planning Areas include “TAMPINES”, “CHANGI”, “WOODLANDS”, and “NOVENA”, so let’s do a further analysis on these areas."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#in-depth-kde-computation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#in-depth-kde-computation",
    "title": "Take-home_Ex01",
    "section": "4.4 In-depth KDE Computation",
    "text": "4.4 In-depth KDE Computation\n\n4.4.1 Data Preparation\nTo do in-depth KDE computation on these 4 planning areas, we will first need to extract their respective boundaries. In the code below, we extracted their boundaries and converted them to sp’s Spatial* class.\n\n\nShow code\nmpsz &lt;- as_Spatial(mpsz2019_new)\ncg = mpsz[mpsz@data$PLN_AREA_N == \"CHANGI\",]\ntp = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nwl = mpsz[mpsz@data$PLN_AREA_N == \"WOODLANDS\",]\nnv = mpsz[mpsz@data$PLN_AREA_N == \"NOVENA\",]\n\n\nPlotting down these boundaries.\n\n\nShow code\npar(mfrow=c(2,2))\nplot(cg, main = \"CHANGI\")\nplot(tp, main = \"TAMPINES\")\nplot(wl, main = \"WOODLANDS\")\nplot(nv, main = \"NOVENA\")\n\n\n\n\n\nTurning the spatial point data frame into generic sp format, then into owin object as done previously.\n\n\nShow code\ncg_sp = as(cg, \"SpatialPolygons\")\ntp_sp = as(tp, \"SpatialPolygons\")\nwl_sp = as(wl, \"SpatialPolygons\")\nnv_sp = as(nv, \"SpatialPolygons\")\n\ncg_owin = as(cg_sp, \"owin\")\ntp_owin = as(tp_sp, \"owin\")\nwl_owin = as(wl_sp, \"owin\")\nnv_owin = as(nv_sp, \"owin\")\n\n\nBy using the code below, we will be able to extract grab origin and destination points for these specific areas.\n\n\nShow code\norigin_cg_ppp = origin_ppp[cg_owin]\norigin_tp_ppp = origin_ppp[tp_owin]\norigin_wl_ppp = origin_ppp[wl_owin]\norigin_nv_ppp = origin_ppp[nv_owin]\n\ndest_cg_ppp = dest_ppp[cg_owin]\ndest_tp_ppp = dest_ppp[tp_owin]\ndest_wl_ppp = dest_ppp[wl_owin]\ndest_nv_ppp = dest_ppp[nv_owin]\n\n\nNext up is the rescale() function used previously as well.\n\n\nShow code\norigin_cg_ppp.km = rescale(origin_cg_ppp, 1000, \"km\")\norigin_tp_ppp.km = rescale(origin_tp_ppp, 1000, \"km\")\norigin_wl_ppp.km = rescale(origin_wl_ppp, 1000, \"km\")\norigin_nv_ppp.km = rescale(origin_nv_ppp, 1000, \"km\")\n\ndest_cg_ppp.km = rescale(dest_cg_ppp, 1000, \"km\")\ndest_tp_ppp.km = rescale(dest_tp_ppp, 1000, \"km\")\ndest_wl_ppp.km = rescale(dest_wl_ppp, 1000, \"km\")\ndest_nv_ppp.km = rescale(dest_nv_ppp, 1000, \"km\")\n\n\nFinally, we plot the four planning areas and the grab hailing origin and destination points\n\n\nShow code\npar(mfrow=c(2,4))\nplot(origin_cg_ppp.km, main = \"CHANGI ORIGIN\")\nplot(origin_tp_ppp.km, main = \"TAMPINES ORIGIN\")\nplot(origin_wl_ppp.km, main = \"WOODLANDS ORIGIN\")\nplot(origin_nv_ppp.km, main = \"NOVENA ORIGIN\")\n\nplot(dest_cg_ppp.km, main = \"CHANGI DESTINATION\")\nplot(dest_tp_ppp.km, main = \"TAMPINES DESTINATION\")\nplot(dest_wl_ppp.km, main = \"WOODLANDS DESTINATION\")\nplot(dest_nv_ppp.km, main = \"NOVENA DESTINATION\")\n\n\n\n\n\n\n\n4.4.2 Computing KDE\nWe will now be computing the KDE of each planning area using the fixed bandwidth method.\n\n4.4.2.1 Changi4.4.2.2 Tampines4.4.2.3 Woodlands4.4.2.4 Novena\n\n\n\n\nShow code\npar(mfrow=c(1,2))\n\nplot(density(origin_cg_ppp.km, \n             sigma=0.5, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Changi Origin\")\n\nplot(density(dest_cg_ppp.km, \n             sigma=0.5, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Changi Destination\")\n\n\n\n\n\n\n\nShow code\ntmap_mode('plot')\ntm_shape(mpsz2019_new[mpsz2019_new$PLN_AREA_N == \"CHANGI\", ]) + \n  tm_polygons('SUBZONE_N')\n\n\n\n\n\nThe hotspot in Changi area is centered around Changi Airport, indicating a likely surge in use of Grab services due to the constant flow of passengers arriving and departing from Singapore.\n\n\n\n\nShow code\npar(mfrow=c(1,2))\n\nplot(density(origin_tp_ppp.km, \n             sigma=0.5, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines Origin\")\n\nplot(density(dest_tp_ppp.km, \n             sigma=0.5, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines Destination\")\n\n\n\n\n\n\n\nShow code\ntmap_mode('plot')\ntm_shape(mpsz2019_new[mpsz2019_new$PLN_AREA_N == \"TAMPINES\", ]) + \n  tm_polygons('SUBZONE_N')\n\n\n\n\n\nThe hotspot in Tampines area is mainly concentrated around the stretch from Tampines West to Tampines East, encompassing the bulk of where most residents of Tampines currently live (Tampines West, Tampines, Tampines East).\n\n\n\n\nShow code\npar(mfrow=c(1,2))\n\nplot(density(origin_wl_ppp.km, \n             sigma=0.5, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Woodlands Origin\")\n\nplot(density(dest_wl_ppp.km, \n             sigma=0.5, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Woodlands Destination\")\n\n\n\n\n\n\n\nShow code\ntmap_mode('plot')\ntm_shape(mpsz2019_new[mpsz2019_new$PLN_AREA_N == \"WOODLANDS\", ]) + \n  tm_polygons('SUBZONE_N')\n\n\n\n\n\nThe rides are concentrated around the lower half of Woodlands area, ranging from Woodlands West to Woodlands South, then Woodlands East. However, one prominent hotspot shared across both the origin and destination map is the Woodlands West region, indicating that this might either be the area with the wealthiest residents in Woodlands, or that there are just more residents concentrated here.\n\n\n\n\nShow code\npar(mfrow=c(1,2))\n\nplot(density(origin_nv_ppp.km, \n             sigma=0.5, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Novena Origin\")\n\nplot(density(dest_nv_ppp.km, \n             sigma=0.5, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Novena Destination\")\n\n\n\n\n\n\n\nShow code\ntmap_mode('plot')\ntm_shape(mpsz2019_new[mpsz2019_new$PLN_AREA_N == \"NOVENA\", ]) + \n  tm_polygons('SUBZONE_N')\n\n\n\n\n\nThe Novena area’s notable hotspots present an interesting distinction. Origin points predominantly converge around the affluent Moulmein area, revealing a concentration in the wealthier section of town. Conversely, the destination points gravitate towards the Malcolm area, characterized by a cluster of prestigious schools, as illustrated in the figure below.\n\n\n\nMoulmein Area\n\n\n\n\n\nGoogle Map View of Malcolm Area, characterized by Prestigious Schools"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#nearest-neighbour-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#nearest-neighbour-analysis",
    "title": "Take-home_Ex01",
    "section": "4.5 Nearest Neighbour Analysis",
    "text": "4.5 Nearest Neighbour Analysis\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat package, to test whether the distribution of Grab ride hailing origin points are randomly distributed.\nUsing 95% confidence interval, the test hypotheses are:\nHo = The distribution of Grab ride hailing origin points are randomly distributed.\nH1= The distribution of Grab ride hailing origin points are not randomly distributed.\nFor this section, we will be making use of the ppp object.\n\nClark-Evans Test\n\nSingaporeChangiTampinesWoodlandsNovena\n\n\n\n\nShow code\nclarkevans.test(originSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  originSG_ppp\nR = 0.27981, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n\n\nShow code\nclarkevans.test(origin_cg_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origin_cg_ppp\nR = 0.11405, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n\n\nShow code\nclarkevans.test(origin_tp_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origin_tp_ppp\nR = 0.32408, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n\n\nShow code\nclarkevans.test(origin_wl_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origin_wl_ppp\nR = 0.31779, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n\n\nShow code\nclarkevans.test(origin_nv_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origin_nv_ppp\nR = 0.34615, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\n\n\nHaving performed the Clark-Evans Test on all 4 planning area and Singapore as a whole, all of their p-values are &lt;2.2e-16 &lt; 0.05, thus we reject Ho. This means that the distribution of Grab ride hailing origin points are not randomly distributed which we explored in earlier sections.\nFurthermore, as their R value ranges from 0.11647 to 0.35838 which is &lt;1, this suggests that the points are clustering."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-preparation-1",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-preparation-1",
    "title": "Take-home_Ex01",
    "section": "5.1 Data Preparation",
    "text": "5.1 Data Preparation\n\n5.1.1 Initial Data Pre-processing\nBefore we begin, let us first convert our sg_roads_new data from SFC_GEOMETRY to SFC_LINESTRING.\n\n\nShow code\nsg_roads_linestring &lt;- st_cast(sg_roads_new, \"LINESTRING\")\n\n\n\n\n5.1.2 Narrowing down the scope\nThen, let us narrow down the scope of our data to the 4 areas mentioned.\n\n\nShow code\n# Roads\ncg_roads &lt;- sg_roads_linestring %&gt;% filter(PLN_AREA_N == \"CHANGI\")\ntp_roads &lt;- sg_roads_linestring %&gt;% filter(PLN_AREA_N == \"TAMPINES\")\nwl_roads &lt;- sg_roads_linestring %&gt;% filter(PLN_AREA_N == \"WOODLANDS\")\nnv_roads &lt;- sg_roads_linestring %&gt;% filter(PLN_AREA_N == \"NOVENA\")\n\n# Grab Origin Points\ncg_origin &lt;- origin_sf_new %&gt;% filter(PLN_AREA_N == \"CHANGI\")\ntp_origin &lt;- origin_sf_new %&gt;% filter(PLN_AREA_N == \"TAMPINES\")\nwl_origin &lt;- origin_sf_new %&gt;% filter(PLN_AREA_N == \"WOODLANDS\")\nnv_origin &lt;- origin_sf_new %&gt;% filter(PLN_AREA_N == \"NOVENA\")\n\n\n\n\n5.1.3 Visualising the data\nBefore we begin our analysis, let us visualise our geospatial data to make sure everything falls into place.\n\nChangiTampinesWoodlandsNovena\n\n\n\n\nShow code\ntm_shape(cg_roads) +\n  tm_lines(\"PLN_AREA_N\") +\ntm_shape(cg_origin) +\n  tm_dots()\n\n\n\n\n\n\n\n\n\nShow code\ntm_shape(tp_roads) +\n  tm_lines(\"PLN_AREA_N\") +\ntm_shape(tp_origin) +\n  tm_dots()\n\n\n\n\n\n\n\n\n\nShow code\ntm_shape(wl_roads) +\n  tm_lines(\"PLN_AREA_N\") +\ntm_shape(wl_origin) +\n  tm_dots()\n\n\n\n\n\n\n\n\n\nShow code\ntm_shape(nv_roads) +\n  tm_lines(\"PLN_AREA_N\") +\ntm_shape(nv_origin) +\n  tm_dots()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#network-constrained-kde-netkde-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#network-constrained-kde-netkde-analysis",
    "title": "Take-home_Ex01",
    "section": "5.2 Network Constrained KDE (NetKDE) Analysis",
    "text": "5.2 Network Constrained KDE (NetKDE) Analysis\nWe will now perform NetKDE analysis by using appropriate functions provided in spNetwork package.\n\n5.2.1 Preparing the lixels objects\n\n\nBefore we can compute NetKDE, the SpatialLines object need to be cut into lixels with a specified minimal distance, and this can be done using lixelize_lines() of spNetwork package.\n\n\nShow code\ncg_lixels &lt;- lixelize_lines(cg_roads, \n                         700, \n                         mindist = 350)\n\ntp_lixels &lt;- lixelize_lines(tp_roads, \n                         700, \n                         mindist = 350)\n\nwl_lixels &lt;- lixelize_lines(wl_roads, \n                         700, \n                         mindist = 350)\n\nnv_lixels &lt;- lixelize_lines(nv_roads, \n                         700, \n                         mindist = 350)\n\n\n\n\n5.2.2 Generating line centre points\nNext, we will use lines_center() of spNetwork to generate a SpatialPointsDataFrame (i.e. samples) with line centre points.\n\n\nShow code\ncg_lines_center &lt;- lines_center(cg_lixels)\ntp_lines_center &lt;- lines_center(tp_lixels)\nwl_lines_center &lt;- lines_center(wl_lixels)\nnv_lines_center &lt;- lines_center(nv_lixels)\n\n\n\n\n5.2.3 Computing NetKDE\nWe are now ready to compute NetKDE. As the code is fairly long, we will split it into 4 tabs.\n\nChangiTampinesWoodlandsNovena\n\n\n\n\nShow code\n# Origin\ncg_o_densities &lt;- nkde(cg_roads, \n                  events = cg_origin,\n                  w = rep(1,nrow(cg_origin)),\n                  samples = cg_lines_center,\n                  kernel_name = \"quartic\", # kernel method\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  # method used to calculate NKDE. spNetwork supports 3 popular                                     methods, namely simple, discontinuous, and continuous\n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, \n                  # we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\n\n\n\nShow code\ntp_o_densities &lt;- nkde(tp_roads, \n                  events = tp_origin,\n                  w = rep(1,nrow(tp_origin)),\n                  samples = tp_lines_center,\n                  kernel_name = \"quartic\", # kernel method\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  # method used to calculate NKDE. spNetwork supports 3 popular                                     methods, namely simple, discontinuous, and continuous\n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, \n                  # we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\n\n\n\nShow code\nwl_o_densities &lt;- nkde(wl_roads, \n                  events = wl_origin,\n                  w = rep(1,nrow(wl_origin)),\n                  samples = wl_lines_center,\n                  kernel_name = \"quartic\", # kernel method\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  # method used to calculate NKDE. spNetwork supports 3 popular                                     methods, namely simple, discontinuous, and continuous\n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, \n                  # we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\n\n\n\nShow code\nnv_o_densities &lt;- nkde(nv_roads, \n                  events = nv_origin,\n                  w = rep(1,nrow(nv_origin)),\n                  samples = nv_lines_center,\n                  kernel_name = \"quartic\", # kernel method\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  # method used to calculate NKDE. spNetwork supports 3 popular                                     methods, namely simple, discontinuous, and continuous\n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, \n                  # we aggregate events within a 5m radius (faster calculation)\n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\n\n\n\n\n5.2.4 Reinsert Density\nBefore we are able to visualise, we first need to insert the computed values back into lines_center and lixels objects as density field.\n\n\nShow code\ncg_lines_center$o_density &lt;- cg_o_densities\ncg_lixels$o_density &lt;- cg_o_densities\n\ntp_lines_center$o_density &lt;- tp_o_densities\ntp_lixels$o_density &lt;- tp_o_densities\n\nwl_lines_center$o_density &lt;- wl_o_densities\nwl_lixels$o_density &lt;- wl_o_densities\n\nnv_lines_center$o_density &lt;- nv_o_densities\nnv_lixels$o_density &lt;- nv_o_densities\n\n\nSince svy21 projection system is in meter, the computed density values are very small i.e. 0.0000005. We will thus need to rescale the density values from number of events per meter to number of events per kilometer.\n\n\nShow code\ncg_lines_center$o_density &lt;- cg_lines_center$o_density*1000\ncg_lixels$o_density &lt;- cg_lixels$o_density*1000\n\ntp_lines_center$o_density &lt;- tp_lines_center$o_density*1000\ntp_lixels$o_density &lt;- tp_lixels$o_density*1000\n\nwl_lines_center$o_density &lt;- wl_lines_center$o_density*1000\nwl_lixels$o_density &lt;- wl_lixels$o_density*1000\n\nnv_lines_center$o_density &lt;- nv_lines_center$o_density*1000\nnv_lixels$o_density &lt;- nv_lixels$o_density*1000\n\n\n\n\n5.2.5 Visualising NetKDE\n\nChangiTampinesWoodlandsNovena\n\n\n\n\nShow code\ntmap_mode('view')\ntm_basemap(leaflet::providers$OpenStreetMap) +\ntm_shape(cg_lixels)+\n  tm_lines(col=\"o_density\")+\ntm_shape(cg_origin)+\n  tm_dots(alpha=0.2)\n\n\n\n\n\n\n\nShow code\ntmap_mode('plot')\n\n\nThis tmap plot further reinforces our observation above that the grab ride traffic are from incoming tourists or locals returning home form the airport, as you can see the denser area being the Changi Airport Terminals. However, it is worth highlighting that there some slight traffic along the Changi Village area and infront of the Japanese School as well.\n\n\n\n\nShow code\ntmap_mode('view')\ntm_basemap(leaflet::providers$OpenStreetMap) +\ntm_shape(tp_lixels)+\n  tm_lines(col=\"o_density\")+\ntm_shape(tp_origin)+\n  tm_dots(alpha=0.2)\n\n\n\n\n\n\n\nShow code\ntmap_mode('plot')\n\n\nAs we have discovered earlier, a huge portion of the grab rides indeed originated from Tampines East, one of the more populated area of Tampines. Particularly along Tampines Avenue 2, there seems to be a higher density, presumably due to it being more convenient to get a ride along the main road.\nSurprisingly, the other higher density area in this network density map is the area around Changi General Hospital.\n\n\n\n\nShow code\ntmap_mode('view')\ntm_basemap(leaflet::providers$OpenStreetMap) +\ntm_shape(wl_lixels)+\n  tm_lines(col=\"o_density\")+\ntm_shape(wl_origin)+\n  tm_dots(alpha=0.2)\n\n\n\n\n\n\n\nShow code\ntmap_mode('plot')\n\n\nThere are 3 main points of to focus on with higher density, mainly:\n\nAlong the route to Woodlands Checkpoint, showing that a significant portion of the rides in Woodlands are people coming in from Malaysia.\nAround the main hub of Woodlands, along the Woodlands MRT stretch. No surprises here, as the area is perhaps the most dense in terms of human traffic due to concentration of malls, bus interchange, and MRT station.\n3 different points around the Sembawang Air Base, which I assume is the entrance. This make sense as well, as military bases in Singapore are generally more inaccessible.\n\n\n\n\n\nShow code\ntmap_mode('view')\ntm_basemap(leaflet::providers$OpenStreetMap) +\ntm_shape(nv_lixels)+\n  tm_lines(col=\"o_density\")+\ntm_shape(nv_origin)+\n  tm_dots(alpha=0.2)\n\n\n\n\n\n\n\nShow code\ntmap_mode('plot')\n\n\nNetwork KDE indicates that the majority of the traffic is along Moulmein Road, which is the main road next to several of the moderately wealthier estates in Singapore."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#network-constrained-g--and-k-function-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#network-constrained-g--and-k-function-analysis",
    "title": "Take-home_Ex01",
    "section": "5.3 Network Constrained G- and K-Function Analysis",
    "text": "5.3 Network Constrained G- and K-Function Analysis\nWe are now going to perform complete spatial randomness (CSR) test by using kfunctions() of spNetwork package. The null hypothesis is defined as:\n\nThe observed spatial point events (i.e distribution of Grab ride hailing points) are uniformly distributed over a street network in the 4 Planning Area specified above.\n\nThe CSR test is based on the assumption of the binomial point process which implies the hypothesis that the childcare centres are randomly and independently distributed over the street network.\nIf this hypothesis is rejected, we may infer that the distribution of Grab ride hailing points are spatially interacting and dependent on each other; as a result, they may form nonrandom patterns.\n\nChangiTampinesWoodlandsNovena\n\n\n\n\nShow code\nkfun_cg &lt;- kfunctions(cg_roads, \n                             cg_origin[c(\"trj_id\",\"PLN_AREA_N\", \"geometry\")],\n                             start = 0,\n                             # A double, the start value for evaluating the k and                                  g functions.\n                             end = 1000, \n                             #  A double, the last value for evaluating the k                                 and g functions.\n                             step = 50, \n                             # A double, the jump between two evaluations of the                               k and g function\n                             width = 50,\n                             # The width of each donut for the g-function\n                             nsim = 50,\n                             # number of Monte Carlo simulations required.\n                             resolution = 50,\n                             verbose = FALSE,\n                             agg = 5,\n                             conf_int = 0.05\n                             #  A double indicating the width confidence interval                               (default = 0.05).\n                             )\n\nkfun_cg\n\n\n$plotk\n\n\n\n\n\n\n$plotg\n\n\n\n\n\n\n$values\n       obs_k    lower_k    upper_k    obs_g    lower_g   upper_g distances\n1    0.00000   0.000000   0.000000 14.46260  0.5420546  0.784789         0\n2   32.75743   2.342464   2.853884 39.67653  2.7725177  3.382085        50\n3   73.63982   5.360448   6.390508 37.85016  3.2858891  4.071459       100\n4  112.49292   8.949365  10.697872 42.18582  3.8956518  4.818003       150\n5  155.30314  13.283265  15.490119 44.29316  4.5988789  5.638500       200\n6  201.05973  18.158245  21.349109 46.36538  5.1842511  6.160652       250\n7  249.41538  23.436936  27.795617 48.76931  5.4340099  6.853537       300\n8  298.82079  29.534173  34.941060 49.48736  5.8968442  7.270713       350\n9  349.27987  36.048584  42.525923 51.11470  6.2927509  8.067794       400\n10 398.82577  42.673436  50.544156 51.05616  6.9932463  8.627020       450\n11 452.44586  50.089907  59.334299 53.86205  7.4026165  9.161075       500\n12 503.59568  58.059554  68.386690 51.20446  8.1052583  9.596591       550\n13 557.14943  66.213398  77.638497 52.96838  8.5918977 10.660603       600\n14 610.77343  75.284911  88.633152 54.93132  9.1269278 11.101193       650\n15 665.84134  84.955259 100.304303 55.50109  9.4717120 11.802664       700\n16 720.21461  95.758498 112.027161 53.62790 10.1322070 12.393890       750\n17 772.87859 106.627493 124.581833 50.75567 10.6291880 13.124825       800\n18 824.82842 118.511719 137.337678 51.92641 11.0529974 13.799954       850\n19 876.22800 130.054478 150.804360 51.00933 11.6053936 14.023371       900\n20 926.42952 142.073144 164.977391 48.61321 12.0163249 15.000552       950\n21 973.50125 154.830550 179.832186 46.47075 12.6120386 15.153725      1000\n\n\nThe blue line represents the empirical network K-function of the Grab ride hailing origin points in Changi planning area. The gray envelop represents the results of the 50 simulations in the interval 2.5% - 97.5%. Because the blue line is above the gray area, we can infer that these origin points in Changi planning area are in clusters, which reinforces our observations made above.\n\n\n\n\nShow code\nkfun_tp &lt;- kfunctions(tp_roads, \n                             tp_origin[c(\"trj_id\",\"PLN_AREA_N\", \"geometry\")],\n                             start = 0,\n                             # A double, the start value for evaluating the k and                                  g functions.\n                             end = 1000, \n                             #  A double, the last value for evaluating the k                                 and g functions.\n                             step = 50, \n                             # A double, the jump between two evaluations of the                               k and g function\n                             width = 50,\n                             # The width of each donut for the g-function\n                             nsim = 50,\n                             # number of Monte Carlo simulations required.\n                             resolution = 50,\n                             verbose = FALSE,\n                             agg = 10,\n                             conf_int = 0.05\n                             #  A double indicating the width confidence interval                               (default = 0.05).\n                             )\n\nkfun_tp\n\n\n$plotk\n\n\n\n\n\n\n$plotg\n\n\n\n\n\n\n$values\n        obs_k    lower_k    upper_k     obs_g    lower_g    upper_g distances\n1    0.000000   0.000000   0.000000  3.063765  0.4421406  0.6130435         0\n2    9.342307   1.377242   1.734585 13.672235  1.7075773  2.0817633        50\n3   24.414290   3.410073   3.924959 15.902540  2.1587204  2.7264608       100\n4   41.077689   5.861521   6.959249 16.683727  2.6969848  3.4020865       150\n5   57.738184   8.816239  10.485047 16.776657  3.1041316  3.8732674       200\n6   75.147922  12.154872  14.685310 18.022491  3.6798582  4.7036786       250\n7   93.338848  16.296618  19.345138 18.347744  4.3864119  5.4137171       300\n8  111.825986  21.052715  25.099644 19.419336  5.0016334  6.1119942       350\n9  132.000374  26.388894  31.651311 20.456079  5.7800621  7.0282198       400\n10 152.970469  32.626633  39.031791 21.155954  6.6395137  7.9580944       450\n11 173.673392  39.640914  47.345050 21.321484  7.3499878  9.1642887       500\n12 195.654094  47.562853  56.535620 22.785122  8.2352853 10.0699145       550\n13 219.049065  56.639730  67.236874 23.243961  9.1369907 11.2673967       600\n14 243.294920  66.362757  78.791625 24.861513  9.9935382 12.0599100       650\n15 268.870827  76.838076  91.276687 26.275782 10.8467461 13.1133517       700\n16 295.985877  88.061912 105.079023 27.748132 11.7536787 14.4680878       750\n17 324.674919 100.112964 119.542755 29.891315 12.5255734 15.1376149       800\n18 355.382270 113.085615 135.042940 32.104196 13.5755301 16.3342258       850\n19 388.200861 127.467598 152.019394 32.632732 14.4512443 17.6732801       900\n20 421.193694 142.679556 170.017347 34.090562 15.4589473 18.5044172       950\n21 456.100292 158.526484 188.698330 35.591952 16.4466123 19.8219816      1000\n\n\nSimilar to Changi planning area, as the blue line is above the grey area, we can infer that the Tampines planning area consists of mainly origin points in clusters.\n\n\n\n\nShow code\nkfun_wl &lt;- kfunctions(wl_roads, \n                             wl_origin[c(\"trj_id\",\"PLN_AREA_N\", \"geometry\")],\n                             start = 0,\n                             # A double, the start value for evaluating the k and                                  g functions.\n                             end = 1000, \n                             #  A double, the last value for evaluating the k                                 and g functions.\n                             step = 50, \n                             # A double, the jump between two evaluations of the                               k and g function\n                             width = 50,\n                             # The width of each donut for the g-function\n                             nsim = 50,\n                             # number of Monte Carlo simulations required.\n                             resolution = 50,\n                             verbose = FALSE,\n                             agg = 5,\n                             conf_int = 0.05\n                             #  A double indicating the width confidence interval                               (default = 0.05).\n                             )\n\nkfun_wl\n\n\n$plotk\n\n\n\n\n\n\n$plotg\n\n\n\n\n\n\n$values\n        obs_k    lower_k    upper_k    obs_g    lower_g   upper_g distances\n1     0.00000   0.000000   0.000000 12.79035  0.9525667  1.238177         0\n2    30.72008   3.133496   3.759995 36.94501  3.9462620  4.893020        50\n3    69.60787   7.720477   9.116881 41.21513  5.0740802  6.286219       100\n4   111.78038  13.485549  15.836522 42.55706  6.2890234  7.791179       150\n5   154.50168  20.493604  24.064728 42.34075  7.3815910  9.088440       200\n6   198.64501  28.531937  33.807306 46.01402  9.0281534 10.902443       250\n7   245.62842  38.409509  45.257535 46.06609 10.6510820 12.703226       300\n8   291.74659  49.824487  58.637132 48.20917 12.0991597 15.071825       350\n9   340.81299  62.740419  74.663726 49.31876 14.2348239 17.144198       400\n10  391.33748  77.880341  93.320495 52.93195 16.1569818 19.799208       450\n11  445.41507  95.196787 114.235103 53.94941 18.0268647 22.520913       500\n12  501.55562 115.224122 137.637280 58.50394 20.7197283 24.838238       550\n13  560.44011 137.307006 163.546454 58.34371 23.1446075 28.063064       600\n14  619.75722 162.547220 192.208177 61.11969 25.4268821 30.737902       650\n15  680.92097 189.478461 224.089320 62.37750 27.6486699 33.196029       700\n16  745.74999 219.255985 258.263352 66.83590 30.3725781 36.154073       750\n17  814.30034 250.842905 295.817634 71.84709 32.3007446 39.598215       800\n18  890.13315 284.529839 336.506815 78.82910 35.4304350 41.818200       850\n19  971.08530 321.563174 380.133810 82.05774 37.8663300 44.697331       900\n20 1054.44490 360.838726 426.995446 86.54017 39.7438238 47.758123       950\n21 1146.03231 401.979153 476.277756 95.30875 42.8362608 50.723377      1000\n\n\nSimilar to Changi planning area, as the blue line is above the grey area, we can infer that the Woodlands planning area consists of mainly origin points in clusters.\n\n\n\n\nShow code\nkfun_nv &lt;- kfunctions(nv_roads, \n                             nv_origin[c(\"trj_id\",\"PLN_AREA_N\", \"geometry\")],\n                             start = 0,\n                             # A double, the start value for evaluating the k and                                  g functions.\n                             end = 1000, \n                             #  A double, the last value for evaluating the k                                 and g functions.\n                             step = 50, \n                             # A double, the jump between two evaluations of the                               k and g function\n                             width = 50,\n                             # The width of each donut for the g-function\n                             nsim = 50,\n                             # number of Monte Carlo simulations required.\n                             resolution = 50,\n                             verbose = FALSE,\n                             agg = 5,\n                             conf_int = 0.05\n                             #  A double indicating the width confidence interval                               (default = 0.05).\n                             )\n\nkfun_nv\n\n\n$plotk\n\n\n\n\n\n\n$plotg\n\n\n\n\n\n\n$values\n        obs_k    lower_k    upper_k    obs_g    lower_g   upper_g distances\n1    0.000000  0.0000000  0.0000000 1.891585 0.07522092 0.1543135         0\n2    3.964585  0.2443574  0.3716798 4.179186 0.29601645 0.4935820        50\n3    8.256602  0.6023205  0.8652618 4.486707 0.40464431 0.6110594       100\n4   12.528708  1.0773185  1.5294183 4.053080 0.51924560 0.7816339       150\n5   16.840637  1.7247715  2.3067381 4.433610 0.64701055 1.0151506       200\n6   21.367167  2.4685737  3.3649195 4.924758 0.80088158 1.1827384       250\n7   26.568472  3.3707823  4.5403570 5.110598 0.94656681 1.3893747       300\n8   31.769778  4.4435653  6.1309476 5.546437 1.21636656 1.7965632       350\n9   37.727717  5.7745332  8.0198777 6.449088 1.37023759 1.9566289       400\n10  44.433441  7.2499695  9.9682102 6.807493 1.48096721 2.1954554       450\n11  51.333855  8.9996302 12.2996163 6.869440 1.70651936 2.3676891       500\n12  58.046216 10.7695343 14.8206234 6.413690 1.84811168 2.5628211       550\n13  64.479817 12.7477339 17.3627587 6.834042 2.05928336 2.7619353       600\n14  71.767397 14.9341185 20.2344280 7.670322 2.22476939 3.0195669       650\n15  79.572674 17.2410778 23.3733528 7.814126 2.48383909 3.1988803       700\n16  87.760692 19.9472611 26.7013256 8.767662 2.65142688 3.5451178       750\n17  96.636761 22.7655014 30.1238775 9.196864 2.79180240 3.7395860       800\n18 105.981854 25.7293164 33.7418932 8.993325 2.91447887 3.8264219       850\n19 115.021639 28.6702332 37.7568099 9.289784 3.02731025 4.1271950       900\n20 124.893279 31.6833842 41.8209521 9.953498 3.22155722 4.1941195       950\n21 134.570229 35.0474187 45.9883018 9.840667 3.40219805 4.3766409      1000\n\n\nSimilar to Changi planning area, as the blue line is above the grey area, we can infer that the Novena planning area consists of mainly origin points in clusters.\n\n\n\nThe results of our G- and K-Function Analysis on all four planning area shows a spatial pattern of clustering among the grab origin points, which supports the idea that grab rides are commonly booked at the same location within an area, possibly due to designated pickup points or taxi stands."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/data/geospatial/MPSZ-2019.html",
    "href": "Take-home_Ex/Take-home_Ex01/data/geospatial/MPSZ-2019.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class_Ex03",
    "section": "",
    "text": "Loading packages\n\n\nShow code\n#install.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\npacman::p_load(sf, spNetwork, tmap, classInt, viridis, tidyverse)\n\n\n\n\n\n\n\nShow code\nnetwork &lt;- st_read(dsn=\"data/geospatial\", layer=\"Punggol_St\")\n\n\nReading layer `Punggol_St' from data source \n  `/Users/jacksontan/Documents/Sashimii0219/IS415-GAA/In-class_Ex/In-class_Ex03/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\nShow code\nchildcare &lt;- st_read(dsn=\"data/geospatial\", layer=\"Punggol_CC\")\n\n\nReading layer `Punggol_CC' from data source \n  `/Users/jacksontan/Documents/Sashimii0219/IS415-GAA/In-class_Ex/In-class_Ex03/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\n\n\nShow code\ntmap_mode('view')\ntm_shape(childcare) +\n  tm_dots() +\n  tm_shape(network) +\n  tm_lines()\n\n\n\n\n\n\n\nShow code\n#differs from Grab data\ntmap_mode('plot')\n\n\n\n\nShow code\nlixels &lt;- lixelize_lines(network,\n                         750,\n                         mindist = 375)\n# # fun fact: Using 375 as people only willing to walk 350m to nearest POI instead of taking transport.\n\n\n\n\nGive center point of the lines\n\n\nShow code\nsamples &lt;- lines_center(lixels)\n\n\n\n\nCalculate density\n\n\nShow code\n#densities &lt;- nkde(network,\n#                  events = childcare,\n#                  w = rep(1,nrow(childcare)),\n#                  samples = samples,\n#                  kernel_name = \"quartic\", # Kernel used\n#                  bw = 300,\n#                  div = \"bw\",\n#                  method = \"simple\",\n#                  digits = 1,\n#                  tol = 1,\n#                  grid_shape = c(1,1),\n#                  max_depth = 8,\n#                  agg = 5, # Aggregate events within a 5m radius (faster calculation)\n#                  sparse = TRUE,\n#                  verbose = FALSE)\n\n\n\n\nShow code\n#lixels$density &lt;- densities\n#childcare$density &lt;- densities\n\n\n\n\nShow code\n#tmap_mode('view')\n#tm_shape(lixels) +\n#  tm_lines(col=\"density\") +\n#  tm_shape(childcare) +\n#  tm_dots()\n\n#tmap_mode('plot')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "Show code\npacman::p_load(sf, spdep, tmap, tidyverse, knitr, GWmodel)\n\n\n\n\nShow code\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\n\nReading layer `Hunan' from data source \n  `/Users/jacksontan/Documents/Sashimii0219/IS415-GAA/In-class_Ex/In-class_Ex04/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nShow code\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\nShow code\nhunan &lt;- left_join(hunan, hunan2012) %&gt;% dplyr::select(1:4, 7, 15)\n\n\n\n\nShow code\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\nShow code\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\n\n\n\nShow code\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\n\n\n\nShow code\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n\nShow code\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch=19, cex=0.6, add=TRUE, col=\"red\")\n\n\n\n\n\nWorking with GWSS (Geographically Weighted Summary Statistics)\n\n\nShow code\nhunan_sp &lt;- hunan %&gt;% as_Spatial()\n\n\n\n\nShow code\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = 6,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)\n\n\nPlot the plot in Spatial Window Sum done in HOE4 but instead use GDPPC_LM, LSD, LVar, LSKE, LCV etc."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#context",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#context",
    "title": "In-class Exercise 5",
    "section": "2.1 Context",
    "text": "2.1 Context"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#loading-r-packages",
    "title": "In-class Exercise 5",
    "section": "2.2 Loading R Packages",
    "text": "2.2 Loading R Packages\nPackages used -\n\n\nShow code\npacman::p_load(sf, sfdep, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#data-importing-and-preparation",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#data-importing-and-preparation",
    "title": "In-class Exercise 5",
    "section": "2.3 Data Importing and Preparation",
    "text": "2.3 Data Importing and Preparation\n\n2.3.1 Dataset\nWe will be using the following dataset in this hands-on exercise:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n2.3.2 Importing Data\nWe will use st_read() of sf package to import Hunan shapefile into R as a simple feature object.\n\n\nShow code\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\n\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package as a R data frame class.\n\n\nShow code\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\n2.3.3 Relational Join\nWe will perform a left_join() from dplyr package to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe.\n\n\nShow code\nhunan_GDPPC &lt;- left_join(hunan,hunan2012) %&gt;%\n  dplyr::select(1:4, 7, 15)\n\n\n\n\n2.3.3 Writing/Reading RDS file\nThis section and the one above will only be run once and omitted in subsequent runs, as by writing to rds file will allow us to read it when we want to run this file.\n\n\nShow code\nwrite_rds(hunan_GDPPC,\n          \"data/RDS/hunan_GDPPC.rds\")\n\n\n\n\nShow code\nhunan_GDPPC &lt;- read_rds(\"data/RDS/hunan_GDPPC.rds\")\n\n\n\n\n2.3.4 Visualising Regional Development Indicator\nBefore we begin our analysis, it is always good to visualise our geographical data. We will now explore the distribution of GDPPC 2012 by using functions of tmap package to prepare a basemap and a choropleth map.\n\n\nShow code\ntmap_mode('plot') +\n  tm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\",\n          style =  \"quantile\",\n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by country, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 0.2) +\n  tm_scale_bar() + \n  tm_grid(alpha = 0.2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class_Ex02",
    "section": "",
    "text": "Installing and loading R packages\nThe R packages that I will be using today are arrow, lubridate, tmap, tidyverse, sf and funModeling.\n\n\nShow code\npacman::p_load(arrow, lubridate, tmap, tidyverse, sf, funModeling)\n\n\n\n\nImporting Data\n\nDataset\nWe will be importing the dataset using read_parquet() function of arrow package.\nWe will then convert the data type of pingtimestamp from character to date-time.\n\n\nShow code\ndf &lt;- read_parquet(\"data/GrabPosisi/part-00000-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet\")\n\ndf$pingtimestamp &lt;- as_datetime(df$pingtimestamp)\n\n\n\n\nWriting dataset to rds file format\n\n\nShow code\n# write_rds(df, \"data/rds/part0.rds\")\n\n\n\n\nExtracting trip starting locations\n\n\nShow code\norigin_df &lt;- df %&gt;%\n  group_by(trj_id) %&gt;%\n  arrange(pingtimestamp) %&gt;% \n  filter(row_number()==1) %&gt;% # Arrange timestamp with earliest ping at the start for each trj_id(starting location)\n  mutate(weekday = wday(pingtimestamp,\n                        label=TRUE,\n                        abbr=TRUE),\n         start_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n\n\nExtracting trip ending locations\n\n\nShow code\ndestination_df &lt;- df %&gt;%\n  group_by(trj_id) %&gt;%\n  arrange(desc(pingtimestamp)) %&gt;%\n  filter(row_number()==1) %&gt;% # Same as previous code but desc, so ending lcoation\n  mutate(weekday = wday(pingtimestamp,\n                        label=TRUE,\n                        abbr=TRUE),\n         end_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\n\n\nWriting starting and ending locations to rds file format\n\n\nShow code\nwrite_rds(origin_df, \"data/rds/origin_df.rds\")\nwrite_rds(destination_df, \"data/rds/destination_df.rds\")\n\n\n\n\nReading starting and ending locations back into the quarto document\n\n\nShow code\norigin_df &lt;- read_rds(\"data/rds/origin_df.rds\")\ndestination_df &lt;- read_rds(\"data/rds/destination_df.rds\")\n\n\n\n\nVisualising frequency distribution\nWe will be using freq() function of funModeling package on the variable ‘weekday’.\n\n\nShow code\nfreq(data = origin_df,\n     input = 'weekday')\n\n\n\n\n\n  weekday frequency percentage cumulative_perc\n1     Wed      4016      14.34           14.34\n2     Tue      4008      14.31           28.65\n3     Thu      4008      14.31           42.96\n4     Sat      4008      14.31           57.27\n5     Fri      4002      14.29           71.56\n6     Sun      3983      14.22           85.78\n7     Mon      3975      14.20          100.00\n\n\n\n\nShow code\norigin_df\n\n\n# A tibble: 28,000 × 12\n# Groups:   trj_id [28,000]\n   trj_id driving_mode osname  pingtimestamp       rawlat rawlng speed bearing\n   &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt;   &lt;dttm&gt;               &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;\n 1 70895  car          android 2019-04-08 00:09:40   1.38   104.  6.80      41\n 2 21926  car          android 2019-04-08 00:09:49   1.29   104. 10.8       68\n 3 47498  car          ios     2019-04-08 00:09:52   1.38   104. 18.3      307\n 4 41322  car          android 2019-04-08 00:10:00   1.28   104. 18.7      230\n 5 18103  car          android 2019-04-08 00:10:09   1.45   104. 14.1      155\n 6 64813  car          ios     2019-04-08 00:10:12   1.31   104. 19.8      109\n 7 81518  car          ios     2019-04-08 00:10:16   1.31   104.  8.75     213\n 8 25201  car          ios     2019-04-08 00:12:09   1.37   104. 12.6      202\n 9 66542  car          android 2019-04-08 00:12:16   1.36   104. 13.9      179\n10 82401  car          android 2019-04-08 00:12:21   1.30   104. 12.7      109\n# ℹ 27,990 more rows\n# ℹ 4 more variables: accuracy &lt;dbl&gt;, weekday &lt;ord&gt;, start_hr &lt;fct&gt;, day &lt;fct&gt;\n\n\n\n\nConverting into sf tibble data.frame\n\n\nShow code\norigin_sf &lt;- st_as_sf(origin_df, \n                       coords = c(\"rawlng\", \"rawlat\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\n\n\n\nVisualising as Point Symbol Map\n\n\nShow code\ntmap_mode(\"plot\")\ntm_shape(origin_sf) +\n  tm_dots()\n\n\n\n\n\n\n\nImporting Master Plan 2019 Planning Subzone Boundary\n\n\nShow code\nmpsz2019 &lt;- st_read(\"data/dataGov/MPSZ2019.kml\") %&gt;%\n  st_transform(crs = 3414)\n\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `/Users/jacksontan/Documents/Sashimii0219/IS415-GAA/In-class_Ex/In-class_Ex02/data/dataGov/MPSZ2019.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\nShow code\ntm_shape(mpsz2019) +\n  tm_polygons() +\ntm_shape(origin_sf) +\n  tm_dots()"
  }
]